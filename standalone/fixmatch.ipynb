{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# FixMatch implementation\n",
    "Unofficial pytorch implementation of FixMatch [[paper]](https://arxiv.org/pdf/2001.07685.pdf) on CIFAR-10.\n",
    "\n",
    "## Initialisation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import torch\n",
    "\n",
    "from metric_utils.metrics import Metrics\n",
    "\n",
    "from sslh.augments.rand_augment import RandAugment\n",
    "from sslh.datasets.utils import split_classes_idx, get_classes_idx, shuffle_classes_idx\n",
    "from sslh.datasets.wrappers.multiple_dataset import MultipleDataset\n",
    "from sslh.datasets.wrappers.onehot_dataset import OneHotDataset\n",
    "from sslh.datasets.wrappers.no_label_dataset import NoLabelDataset\n",
    "from sslh.models.wrn28_2 import WideResNet28\n",
    "from sslh.utils.display import ColumnDisplay\n",
    "from sslh.utils.misc import reset_seed, get_datetime\n",
    "from sslh.utils.other_metrics import CategoricalAccuracyOnehot\n",
    "from sslh.utils.recorder.recorder import Recorder\n",
    "from sslh.utils.torch import CrossEntropyWithVectors, get_lr, get_reduction_from_name\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.nn import Module\n",
    "from torch.nn.functional import one_hot\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import RandomHorizontalFlip, RandomChoice, Compose, ToTensor, Normalize, RandomCrop\n",
    "from typing import Callable, Dict, Iterable, Optional, Sized"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "reset_seed(1234)\n",
    "\n",
    "# Hyperparameters\n",
    "nb_epochs = 200\n",
    "lambda_u = 1.0\n",
    "lr = 1e-3\n",
    "threshold = 0.95\n",
    "bsize = 128\n",
    "mu = 7  # = bsize_u / bsize_s, must be in range [1..bsize[\n",
    "\n",
    "dataset_root = osp.join(\"..\", \"dataset\")\n",
    "tensorboard_root = osp.join(\"..\", \"results\", \"tensorboard\")\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "# Same as CrossEntropy but accept non-\"onehot encoding\" vectors as targets (labels)\n",
    "criterion_s = CrossEntropyWithVectors(reduction=\"none\")\n",
    "criterion_u = CrossEntropyWithVectors(reduction=\"none\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Learning rate Scheduler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class CosineLRScheduler(LambdaLR):\n",
    "\t\"\"\"\n",
    "\t\tScheduler that decreases the learning rate from lr0 to almost 0 by using the following rule :\n",
    "\t\tlr = lr0 * cos(7 * pi * epoch / (16 * nb_epochs))\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, optim: Optimizer, nb_epochs: int):\n",
    "\t\tlr_lambda = lambda p_epoch: math.cos(7.0 * math.pi * p_epoch / (16.0 * nb_epochs))\n",
    "\t\tsuper().__init__(optim, lr_lambda)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Build objects"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Build WideResNet-28-2 model\n",
    "model = WideResNet28(num_classes=10, width=2).to(device)\n",
    "activation = torch.softmax\n",
    "optim = Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Build metrics. You can add a metric in this dictionary.\n",
    "metrics_s = {\"acc_s\": CategoricalAccuracyOnehot(dim=1)}\n",
    "metrics_u = {\"acc_u\": CategoricalAccuracyOnehot(dim=1)}\n",
    "metrics_val = {\"acc\": CategoricalAccuracyOnehot(dim=1)}\n",
    "\n",
    "# Tensorboard writer and the Recorder wrapper for tracking max, std & min of the values stored.\n",
    "writer = SummaryWriter(osp.join(tensorboard_root, \"CIFAR10_%s_WideResNet28_FixMatch\" % get_datetime()))\n",
    "recorder = Recorder(writer)\n",
    "\n",
    "# Class for managing how the values are print in terminal\n",
    "display = ColumnDisplay()\n",
    "\n",
    "sched = CosineLRScheduler(optim, nb_epochs=nb_epochs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build Dataloaders"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ZipCycle class"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ZipCycle(Iterable, Sized):\n",
    "\t\"\"\"\n",
    "\t\tZip through a list of iterables and sized objects of different lengths.\n",
    "\t\tReset the iterators when there and finish iteration when the longest one is over.\n",
    "\n",
    "\t\tExample :\n",
    "\t\tr1 = range(1, 4)\n",
    "\t\tr2 = range(1, 6)\n",
    "\t\titers = ZipCycle([r1, r2])\n",
    "\t\tfor v1, v2 in iters:\n",
    "\t\t\tprint(v1, v2)\n",
    "\n",
    "\t\twill print :\n",
    "\t\t1 1\n",
    "\t\t2 2\n",
    "\t\t3 3\n",
    "\t\t1 4\n",
    "\t\t2 5\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(self, iterables: list):\n",
    "\t\tfor iterable in iterables:\n",
    "\t\t\tif len(iterable) == 0:\n",
    "\t\t\t\traise RuntimeError(\"An iterable is empty.\")\n",
    "\n",
    "\t\tself._iterables = iterables\n",
    "\t\tself._len = max([len(iterable) for iterable in self._iterables])\n",
    "\n",
    "\tdef __iter__(self) -> list:\n",
    "\t\tcur_iters = [iter(iterable) for iterable in self._iterables]\n",
    "\t\tcur_count = [0 for _ in self._iterables]\n",
    "\n",
    "\t\tfor _ in range(len(self)):\n",
    "\t\t\titems = []\n",
    "\n",
    "\t\t\tfor i, _ in enumerate(cur_iters):\n",
    "\t\t\t\tif cur_count[i] < len(self._iterables[i]):\n",
    "\t\t\t\t\titem = next(cur_iters[i])\n",
    "\t\t\t\t\tcur_count[i] += 1\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tcur_iters[i] = iter(self._iterables[i])\n",
    "\t\t\t\t\titem = next(cur_iters[i])\n",
    "\t\t\t\t\tcur_count[i] = 1\n",
    "\t\t\t\titems.append(item)\n",
    "\n",
    "\t\t\tyield items\n",
    "\n",
    "\tdef __len__(self) -> int:\n",
    "\t\treturn self._len"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/labbeti/anaconda3/envs/env_ssl/lib/python3.8/site-packages/torchvision/transforms/functional.py:74: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729062494/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n"
     ]
    }
   ],
   "source": [
    "def get_loaders() -> (DataLoader, DataLoader):\n",
    "\taugm_weak = Compose([\n",
    "\t\tRandomChoice([\n",
    "\t\t\tRandomHorizontalFlip(0.5),\n",
    "\t\t\tRandomCrop((32, 32), padding=8),\n",
    "\t\t]),\n",
    "\t\tlambda img: np.array(img),\n",
    "\t])\n",
    "\taugm_strong = Compose([\n",
    "\t\tlambda img: np.array(img),\n",
    "\t\tRandAugment(\n",
    "\t\t\tratio=1.0,\n",
    "\t\t\tmagnitude_m=2.0,\n",
    "\t\t\tnb_choices_n=1\n",
    "\t\t)\n",
    "\t])\n",
    "\n",
    "\t# Add postprocessing after each augmentation (shape : [32, 32, 3] -> [3, 32, 32])\n",
    "\tpost_process_fn = Compose([\n",
    "\t\tToTensor(),\n",
    "\t\tNormalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "\t])\n",
    "\n",
    "\ttransform_augm_weak = Compose([\n",
    "\t\taugm_weak,\n",
    "\t\tpost_process_fn,\n",
    "\t])\n",
    "\ttransform_augm_strong = Compose([\n",
    "\t\taugm_strong,\n",
    "\t\tpost_process_fn,\n",
    "\t])\n",
    "\n",
    "\tdataset_train_augm_weak = CIFAR10(dataset_root, train=True, download=True, transform=transform_augm_weak)\n",
    "\tdataset_train_augm_strong = CIFAR10(dataset_root, train=True, download=True, transform=transform_augm_strong)\n",
    "\n",
    "\t# Use 4000 data with labels (8%) and 46000 data without labels (92%)\n",
    "\tcls_idx_all = get_classes_idx(dataset_train_augm_weak, 10, is_one_hot=False)\n",
    "\tcls_idx_all = shuffle_classes_idx(cls_idx_all)\n",
    "\tidx_split = split_classes_idx(cls_idx_all, ratios=[0.08, 0.92])\n",
    "\tidx_s, idx_u = idx_split\n",
    "\n",
    "\tdataset_train_augm_weak_s = Subset(dataset_train_augm_weak, idx_s)\n",
    "\tdataset_train_augm_weak_u = Subset(dataset_train_augm_weak, idx_u)\n",
    "\tdataset_train_augm_strong_u = Subset(dataset_train_augm_strong, idx_u)\n",
    "\n",
    "\tdataset_train_augm_weak_s = OneHotDataset(dataset_train_augm_weak_s, nb_classes=10)\n",
    "\tdataset_train_augm_weak_u = NoLabelDataset(dataset_train_augm_weak_u)\n",
    "\tdataset_train_augm_strong_u = NoLabelDataset(dataset_train_augm_strong_u)\n",
    "\n",
    "\tdataset_train_augms_weak_strong_u = MultipleDataset([dataset_train_augm_weak_u, dataset_train_augm_strong_u])\n",
    "\n",
    "\t# Build loaders for supervised data and unsupervised data\n",
    "\tbsize_s = int(bsize / (mu + 1))\n",
    "\tbsize_u = int(bsize * mu / (mu + 1))\n",
    "\tloader_train_s_augm = DataLoader(\n",
    "\t\tdataset=dataset_train_augm_weak_s, batch_size=bsize_s, shuffle=True, num_workers=1, drop_last=True)\n",
    "\tloader_train_u_augms = DataLoader(\n",
    "\t\tdataset=dataset_train_augms_weak_strong_u, batch_size=bsize_u, shuffle=True, num_workers=mu, drop_last=True)\n",
    "\n",
    "\tloader_train = ZipCycle([loader_train_s_augm, loader_train_u_augms])\n",
    "\n",
    "\t# Create validation dataloader\n",
    "\tdataset_val = CIFAR10(dataset_root, train=False, download=True, transform=post_process_fn)\n",
    "\tdataset_val = OneHotDataset(dataset_val, nb_classes=10)\n",
    "\n",
    "\tloader_val = DataLoader(dataset=dataset_val, batch_size=bsize, shuffle=False, drop_last=False)\n",
    "\treturn loader_train, loader_val\n",
    "\n",
    "loader_train, loader_val = get_loaders()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Criterion"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cross Entropy with probabilities"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class CrossEntropyWithVectors(Module):\n",
    "\t\"\"\"\n",
    "\t\tCompute Cross-Entropy between two distributions.\n",
    "\t\tInput and targets must be a batch of probabilities distributions of shape (batch_size, nb_classes) tensor.\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, reduction: str = \"batchmean\", dim: Optional[int] = 1, log_input: bool = False):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.reduce_fn = get_reduction_from_name(reduction)\n",
    "\t\tself.dim = dim\n",
    "\t\tself.log_input = log_input\n",
    "\n",
    "\tdef forward(self, input_: Tensor, targets: Tensor, dim: Optional[int] = None) -> Tensor:\n",
    "\t\t\"\"\"\n",
    "\t\t\tCompute cross-entropy with targets.\n",
    "\t\t\tInput and target must be a (batch_size, nb_classes) tensor.\n",
    "\t\t\"\"\"\n",
    "\t\tif dim is None:\n",
    "\t\t\tdim = self.dim\n",
    "\t\tif not self.log_input:\n",
    "\t\t\tinput_ = torch.log(input_)\n",
    "\t\tloss = -torch.sum(input_ * targets, dim=dim)\n",
    "\t\treturn self.reduce_fn(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### FixMatch loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class FixMatchLoss(Module):\n",
    "\t\"\"\"\n",
    "\t\tFixMatch loss module.\n",
    "\n",
    "\t\tLoss formula : loss = CE(pred_s, label_s) + lambda_u * mask * CE(pred_u, label_u)\n",
    "\n",
    "\t\tThe mask used is 1 if the confidence prediction on weakly augmented data is above a specific threshold.\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(\n",
    "\t\tself,\n",
    "\t\tcriterion_s: Callable = CrossEntropyWithVectors(reduction=\"none\"),\n",
    "\t\tcriterion_u: Callable = CrossEntropyWithVectors(reduction=\"none\"),\n",
    "\t\treduction: str = \"batchmean\",\n",
    "\t):\n",
    "\t\t\"\"\"\n",
    "\t\t\t:param criterion_s: The criterion used for labeled loss component.\n",
    "\t\t\t:param criterion_u: The criterion used for unlabeled loss component. No reduction must be applied.\n",
    "\t\t\t:param reduction: The main reduction to use. Can be 'none', 'mean', 'batchmean' or 'sum'.\n",
    "\t\t\"\"\"\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.criterion_s = criterion_s\n",
    "\t\tself.criterion_u = criterion_u\n",
    "\t\tself.reduce_fn = get_reduction_from_name(reduction)\n",
    "\n",
    "\tdef forward(\n",
    "\t\tself,\n",
    "\t\tpred_s_augm_weak: Tensor,\n",
    "\t\tpred_u_augm_strong: Tensor,\n",
    "\t\tmask: Tensor,\n",
    "\t\tlabels_s: Tensor,\n",
    "\t\tlabels_u: Tensor,\n",
    "\t\tlambda_s: float = 1.0,\n",
    "\t\tlambda_u: float = 1.0,\n",
    "\t) -> (Tensor, Tensor, Tensor):\n",
    "\t\t\"\"\"\n",
    "\t\t\tCompute FixMatch loss.\n",
    "\n",
    "\t\t\tGeneric :\n",
    "\t\t\t\tloss = lambda_s * mean(criterion_s(pred_s, labels_s)) + lambda_u * mean(criterion_u(pred_u, labels_u) * mask)\n",
    "\n",
    "\t\t\t:param pred_s_augm_weak: Output of the model for labeled batch s of shape (batch_size, nb_classes).\n",
    "\t\t\t:param pred_u_augm_strong: Output of the model for unlabeled batch u of shape (batch_size, nb_classes).\n",
    "\t\t\t:param mask: Binary confidence mask used to avoid using low-confidence labels as targets of shape (batch_size).\n",
    "\t\t\t:param labels_s: True label of labeled batch s of shape (batch_size, nb_classes).\n",
    "\t\t\t:param labels_u: Guessed label of unlabeled batch u of shape (batch_size, nb_classes).\n",
    "\t\t\t:param lambda_s: Coefficient used to multiply the supervised loss component.\n",
    "\t\t\t:param lambda_u: Coefficient used to multiply the unsupervised loss component.\n",
    "\t\t\"\"\"\n",
    "\t\tloss_s = self.criterion_s(pred_s_augm_weak, labels_s)\n",
    "\n",
    "\t\tloss_u = self.criterion_u(pred_u_augm_strong, labels_u)\n",
    "\t\tloss_u *= mask\n",
    "\n",
    "\t\tloss_s = self.reduce_fn(loss_s)\n",
    "\t\tloss_u = self.reduce_fn(loss_u)\n",
    "\n",
    "\t\tloss = lambda_s * loss_s + lambda_u * loss_u\n",
    "\n",
    "\t\treturn loss, loss_s, loss_u\n",
    "\n",
    "criterion = FixMatchLoss(criterion_s, criterion_u)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def guess_label(batch_u_augm_weak: Tensor) -> (Tensor, Tensor):\n",
    "\tlogits_u_augm_weak = model(batch_u_augm_weak)\n",
    "\tpred_u_augm_weak = activation(logits_u_augm_weak, dim=1)\n",
    "\n",
    "\tnb_classes = pred_u_augm_weak.shape[1]\n",
    "\tlabels_u = one_hot(pred_u_augm_weak.argmax(dim=1), nb_classes)\n",
    "\treturn labels_u, pred_u_augm_weak"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def confidence_mask(pred_weak: Tensor, threshold: float, dim: int) -> Tensor:\n",
    "\tmax_values, _ = pred_weak.max(dim=dim)\n",
    "\treturn (max_values > threshold).float()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def reset_metrics(metrics: Dict[str, Metrics]):\n",
    "\tfor name, metric in metrics.items():\n",
    "\t\tmetric.reset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def train(epoch: int):\n",
    "\tmodel.train()\n",
    "\treset_metrics(metrics_s)\n",
    "\treset_metrics(metrics_u)\n",
    "\n",
    "\trecorder.start_record(epoch)\n",
    "\tkeys = list(metrics_s.keys()) + list(metrics_u.keys()) + [\"loss\", \"loss_s\", \"loss_u\", \"labels_used\"]\n",
    "\tdisplay.print_header(\"train\", keys)\n",
    "\n",
    "\titer_loader = iter(loader_train)\n",
    "\n",
    "\tfor i, ((batch_s_augm_weak, labels_s), (batch_u_augm_weak, batch_u_augm_strong)) in enumerate(iter_loader):\n",
    "\t\tbatch_s_augm_weak = batch_s_augm_weak.to(device).float()\n",
    "\t\tlabels_s = labels_s.to(device).float()\n",
    "\t\tbatch_u_augm_weak = batch_u_augm_weak.to(device).float()\n",
    "\t\tbatch_u_augm_strong = batch_u_augm_strong.to(device).float()\n",
    "\n",
    "\t\t# Guess label with prediction of weakly augment of u\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tlabels_u, pred_u_augm_weak = guess_label(batch_u_augm_weak)\n",
    "\t\t\tmask = confidence_mask(pred_u_augm_weak, threshold, dim=1)\n",
    "\n",
    "\t\toptim.zero_grad()\n",
    "\n",
    "\t\t# Compute predictions\n",
    "\t\tlogits_s_augm_weak = model(batch_s_augm_weak)\n",
    "\t\tlogits_u_augm_strong = model(batch_u_augm_strong)\n",
    "\n",
    "\t\tpred_s_augm_weak = activation(logits_s_augm_weak, dim=1)\n",
    "\t\tpred_u_augm_strong = activation(logits_u_augm_strong, dim=1)\n",
    "\n",
    "\t\t# Update model\n",
    "\t\tloss, loss_s, loss_u = criterion(\n",
    "\t\t\tpred_s_augm_weak,\n",
    "\t\t\tpred_u_augm_strong,\n",
    "\t\t\tmask,\n",
    "\t\t\tlabels_s,\n",
    "\t\t\tlabels_u,\n",
    "\t\t\tlambda_u=lambda_u\n",
    "\t\t)\n",
    "\n",
    "\t\tloss.backward()\n",
    "\t\toptim.step()\n",
    "\n",
    "\t\t# Compute metrics\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\trecorder.add_point(\"train/loss\", loss.item())\n",
    "\t\t\trecorder.add_point(\"train/loss_s\", loss_s.item())\n",
    "\t\t\trecorder.add_point(\"train/loss_u\", loss_u.item())\n",
    "\n",
    "\t\t\tproportion_labels_used = mask.sum() / mask.shape[0]\n",
    "\t\t\trecorder.add_point(\"train/labels_used\", proportion_labels_used.item())\n",
    "\n",
    "\t\t\tfor metric_name, metric in metrics_s.items():\n",
    "\t\t\t\t_mean = metric(pred_s_augm_weak, labels_s)\n",
    "\t\t\t\trecorder.add_point(\"train/{:s}\".format(metric_name), metric.value.item())\n",
    "\n",
    "\t\t\tfor metric_name, metric in metrics_u.items():\n",
    "\t\t\t\t_mean = metric(pred_u_augm_strong, labels_u)\n",
    "\t\t\t\trecorder.add_point(\"train/{:s}\".format(metric_name), metric.value.item())\n",
    "\n",
    "\t\t\tdisplay.print_current_values(recorder.get_current_means(), i, len(loader_train), epoch)\n",
    "\n",
    "\trecorder.add_point(\"train/lr\", get_lr(optim))\n",
    "\trecorder.end_record(epoch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def val(epoch: int):\n",
    "\tmodel.eval()\n",
    "\treset_metrics(metrics_val)\n",
    "\tcurrent_means = {\"val/%s\" % name: 0.0 for name in metrics_val.keys()}\n",
    "\n",
    "\tdisplay.print_header(\"val\", metrics_val.keys(), False)\n",
    "\n",
    "\tfor i, (x, y) in enumerate(loader_val):\n",
    "\t\tx = x.to(device).float()\n",
    "\t\ty = y.to(device).float()\n",
    "\n",
    "\t\t# Compute logits\n",
    "\t\tlogits = model(x)\n",
    "\t\tpred = activation(logits, dim=1)\n",
    "\n",
    "\t\tfor name, metric in metrics_val.items():\n",
    "\t\t\tcurrent_means[\"val/{:s}\".format(name)] = metric(pred, y)\n",
    "\n",
    "\t\tdisplay.print_current_values(current_means, i, len(loader_val), epoch)\n",
    "\n",
    "\tfor name, mean_ in current_means.items():\n",
    "\t\twriter.add_scalar(name, mean_, epoch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Start learning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch   1 - 100% - 2.8384e-01 - 5.8691e-01 - 1.5244e-04 - 1.9456e+00 - 1.9455e+00 - 4.2729e-05 -   13.70    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch   1 - 100% - 3.7866e-01 -    1.77    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch   2 - 100% - 3.8095e-01 - 6.1433e-01 - 1.2848e-03 - 1.6743e+00 - 1.6740e+00 - 2.7921e-04 -   13.26    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch   2 - 100% - 4.3750e-01 -    1.79    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch   3 - 100% - 4.3628e-01 - 6.2267e-01 - 8.6455e-03 - 1.5454e+00 - 1.5428e+00 - 2.5869e-03 -   13.51    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch   3 - 100% - 4.9773e-01 -    1.78    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch   4 - 100% - 4.9284e-01 - 6.3158e-01 - 1.7792e-02 - 1.4141e+00 - 1.4094e+00 - 4.7107e-03 -   13.13    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch   4 - 100% - 5.4104e-01 -    1.72    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch   5 - 100% - 5.3369e-01 - 6.4534e-01 - 3.9046e-02 - 1.3223e+00 - 1.3125e+00 - 9.8385e-03 -   13.01    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch   5 - 100% - 5.5222e-01 -    1.75    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch   6 - 100% - 5.6082e-01 - 6.6159e-01 - 6.9207e-02 - 1.2306e+00 - 1.2123e+00 - 1.8232e-02 -   13.22    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch   6 - 100% - 5.6131e-01 -    1.82    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch   7 - 100% - 5.8796e-01 - 6.6496e-01 - 9.0505e-02 - 1.1784e+00 - 1.1554e+00 - 2.3038e-02 -   13.53    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch   7 - 100% - 5.8811e-01 -    1.74    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch   8 - 100% - 6.2012e-01 - 6.7289e-01 - 1.1346e-01 - 1.1035e+00 - 1.0761e+00 - 2.7399e-02 -   13.21    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch   8 - 100% - 6.1877e-01 -    1.78    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch   9 - 100% - 6.4741e-01 - 6.8384e-01 - 1.4983e-01 - 1.0375e+00 - 1.0021e+00 - 3.5385e-02 -   13.73    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch   9 - 100% - 6.3459e-01 -    1.76    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  10 - 100% - 6.6570e-01 - 6.9183e-01 - 1.7101e-01 - 9.9607e-01 - 9.5835e-01 - 3.7721e-02 -   13.49    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  10 - 100% - 6.3439e-01 -    1.80    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  11 - 100% - 6.8582e-01 - 6.9270e-01 - 1.9164e-01 - 9.3540e-01 - 8.9125e-01 - 4.4148e-02 -   13.83    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  11 - 100% - 6.5704e-01 -    1.86    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  12 - 100% - 7.0534e-01 - 6.9904e-01 - 2.2613e-01 - 8.9024e-01 - 8.4182e-01 - 4.8424e-02 -   13.93    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  12 - 100% - 6.4043e-01 -    1.80    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  13 - 100% - 7.2409e-01 - 7.0046e-01 - 2.4680e-01 - 8.5454e-01 - 7.9824e-01 - 5.6305e-02 -   13.74    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  13 - 100% - 6.4458e-01 -    1.76    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  14 - 100% - 7.3567e-01 - 7.0719e-01 - 2.6921e-01 - 8.1289e-01 - 7.5418e-01 - 5.8702e-02 -   13.42    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  14 - 100% - 6.5971e-01 -    1.75    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  15 - 100% - 7.5640e-01 - 7.1052e-01 - 2.9155e-01 - 7.6304e-01 - 6.9749e-01 - 6.5551e-02 -   13.25    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  15 - 100% - 6.7494e-01 -    1.74    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  16 - 100% - 7.6357e-01 - 7.1385e-01 - 3.0767e-01 - 7.4176e-01 - 6.7330e-01 - 6.8464e-02 -   14.04    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  16 - 100% - 6.8443e-01 -    1.78    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  17 - 100% - 7.8095e-01 - 7.1803e-01 - 3.2263e-01 - 7.1521e-01 - 6.4327e-01 - 7.1939e-02 -   13.69    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  17 - 100% - 6.9729e-01 -    1.78    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  18 - 100% - 7.9299e-01 - 7.1790e-01 - 3.3868e-01 - 6.6277e-01 - 5.8628e-01 - 7.6498e-02 -   13.78    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  18 - 100% - 6.9877e-01 -    1.74    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  19 - 100% - 7.9878e-01 - 7.2446e-01 - 3.5684e-01 - 6.4786e-01 - 5.6631e-01 - 8.1546e-02 -   13.86    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  19 - 100% - 7.0154e-01 -    1.74    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  20 - 100% - 8.1052e-01 - 7.2652e-01 - 3.7247e-01 - 6.1612e-01 - 5.3246e-01 - 8.3668e-02 -   13.90    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  20 - 100% - 7.0955e-01 -    1.81    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  21 - 100% - 8.2241e-01 - 7.2829e-01 - 3.9360e-01 - 5.9875e-01 - 5.0722e-01 - 9.1536e-02 -   13.63    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  21 - 100% - 7.1044e-01 -    1.83    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  22 - 100% - 8.4024e-01 - 7.3158e-01 - 3.9797e-01 - 5.6273e-01 - 4.6789e-01 - 9.4843e-02 -   13.79    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  22 - 100% - 7.0837e-01 -    1.77    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  23 - 100% - 8.5122e-01 - 7.3223e-01 - 4.2008e-01 - 5.3588e-01 - 4.3347e-01 - 1.0241e-01 -   13.47    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  23 - 100% - 6.9907e-01 -    1.76    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  24 - 100% - 8.5305e-01 - 7.3489e-01 - 4.3678e-01 - 5.2247e-01 - 4.1761e-01 - 1.0486e-01 -   13.54    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  24 - 100% - 7.1143e-01 -    1.74    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  25 - 100% - 8.6753e-01 - 7.3909e-01 - 4.4307e-01 - 4.9517e-01 - 3.9005e-01 - 1.0512e-01 -   13.76    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  25 - 100% - 7.2132e-01 -    1.74    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  26 - 100% - 8.6997e-01 - 7.3985e-01 - 4.5507e-01 - 4.7537e-01 - 3.6643e-01 - 1.0894e-01 -   13.36    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  26 - 100% - 7.2142e-01 -    1.78    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  27 - 100% - 8.6966e-01 - 7.4024e-01 - 4.5965e-01 - 4.7796e-01 - 3.7007e-01 - 1.0789e-01 -   13.40    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  27 - 100% - 7.2261e-01 -    1.80    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  28 - 100% - 8.8628e-01 - 7.4601e-01 - 4.7655e-01 - 4.3714e-01 - 3.2106e-01 - 1.1609e-01 -   13.78    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  28 - 100% - 7.2033e-01 -    1.74    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  29 - 100% - 8.9482e-01 - 7.4841e-01 - 4.9305e-01 - 4.2710e-01 - 3.0855e-01 - 1.1854e-01 -   13.76    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  29 - 100% - 7.1826e-01 -    1.80    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  30 - 100% - 8.9634e-01 - 7.4597e-01 - 4.9059e-01 - 4.2472e-01 - 3.0269e-01 - 1.2203e-01 -   13.75    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  30 - 100% - 7.1915e-01 -    1.78    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  31 - 100% - 9.0046e-01 - 7.5133e-01 - 4.9521e-01 - 4.1521e-01 - 2.9517e-01 - 1.2004e-01 -   13.55    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  31 - 100% - 7.3002e-01 -    1.78    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  32 - 100% - 9.0473e-01 - 7.5259e-01 - 5.0534e-01 - 3.9673e-01 - 2.7519e-01 - 1.2154e-01 -   13.92    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  32 - 100% - 7.3151e-01 -    1.76    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  33 - 100% - 9.0046e-01 - 7.5039e-01 - 5.0727e-01 - 4.1411e-01 - 2.8839e-01 - 1.2572e-01 -   13.94    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  33 - 100% - 7.3418e-01 -    1.85    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  34 - 100% - 9.0854e-01 - 7.5527e-01 - 5.1631e-01 - 3.8593e-01 - 2.6061e-01 - 1.2532e-01 -   13.48    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  34 - 100% - 7.4357e-01 -    1.74    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  35 - 100% - 9.1829e-01 - 7.5520e-01 - 5.2546e-01 - 3.7007e-01 - 2.3871e-01 - 1.3136e-01 -   13.56    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  35 - 100% - 7.3873e-01 -    1.74    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  36 - 100% - 9.2515e-01 - 7.5895e-01 - 5.3530e-01 - 3.4490e-01 - 2.1996e-01 - 1.2495e-01 -   13.39    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  36 - 100% - 7.4684e-01 -    1.75    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  37 - 100% - 9.2683e-01 - 7.6204e-01 - 5.3963e-01 - 3.5541e-01 - 2.2234e-01 - 1.3307e-01 -   13.35    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  37 - 100% - 7.3744e-01 -    1.79    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  38 - 100% - 9.2744e-01 - 7.6527e-01 - 5.3811e-01 - 3.4692e-01 - 2.1559e-01 - 1.3132e-01 -   13.59    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  38 - 100% - 7.3180e-01 -    1.79    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  39 - 100% - 9.2576e-01 - 7.6344e-01 - 5.4395e-01 - 3.5083e-01 - 2.1655e-01 - 1.3428e-01 -   13.72    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  39 - 100% - 7.3269e-01 -    1.75    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  40 - 100% - 9.3476e-01 - 7.6514e-01 - 5.5083e-01 - 3.2049e-01 - 1.8584e-01 - 1.3465e-01 -   13.46    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  40 - 100% - 7.4555e-01 -    1.74    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  41 - 100% - 9.2912e-01 - 7.6838e-01 - 5.5490e-01 - 3.3150e-01 - 1.9952e-01 - 1.3198e-01 -   13.51    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  41 - 100% - 7.4110e-01 -    1.75    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  42 - 100% - 9.3552e-01 - 7.6646e-01 - 5.6161e-01 - 3.2570e-01 - 1.8448e-01 - 1.4122e-01 -   13.45    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  42 - 100% - 7.5653e-01 -    1.77    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  43 - 100% - 9.4101e-01 - 7.6966e-01 - 5.6836e-01 - 3.1151e-01 - 1.7368e-01 - 1.3783e-01 -   13.38    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  43 - 100% - 7.5010e-01 -    1.78    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  44 - 100% - 9.4116e-01 - 7.7232e-01 - 5.6740e-01 - 3.1846e-01 - 1.7960e-01 - 1.3886e-01 -   13.55    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  44 - 100% - 7.4990e-01 -    1.74    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  45 - 100% - 9.4207e-01 - 7.6966e-01 - 5.6357e-01 - 3.0614e-01 - 1.7082e-01 - 1.3532e-01 -   13.71    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  45 - 100% - 7.5277e-01 -    1.73    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  46 - 100% - 9.4588e-01 - 7.7395e-01 - 5.7241e-01 - 2.9477e-01 - 1.6105e-01 - 1.3373e-01 -   13.53    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  46 - 100% - 7.5000e-01 -    1.75    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  47 - 100% - 9.4909e-01 - 7.7842e-01 - 5.7894e-01 - 2.8707e-01 - 1.5182e-01 - 1.3525e-01 -   13.43    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  47 - 100% - 7.5564e-01 -    1.75    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  48 - 100% - 9.4741e-01 - 7.7794e-01 - 5.8476e-01 - 2.9313e-01 - 1.5422e-01 - 1.3891e-01 -   13.58    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  48 - 100% - 7.5811e-01 -    1.76    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  49 - 100% - 9.4848e-01 - 7.7491e-01 - 5.8158e-01 - 2.8108e-01 - 1.4248e-01 - 1.3861e-01 -   13.80    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  49 - 100% - 7.6553e-01 -    1.74    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  50 - 100% - 9.5335e-01 - 7.8055e-01 - 5.9061e-01 - 2.8298e-01 - 1.4622e-01 - 1.3677e-01 -   13.53    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  50 - 100% - 7.5425e-01 -    1.79    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  51 - 100% - 9.5503e-01 - 7.8123e-01 - 5.9397e-01 - 2.7631e-01 - 1.3893e-01 - 1.3738e-01 -   13.99    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  51 - 100% - 7.5524e-01 -    1.82    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  52 - 100% - 9.5335e-01 - 7.8469e-01 - 5.9621e-01 - 2.7380e-01 - 1.3726e-01 - 1.3654e-01 -   13.56    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  52 - 100% - 7.5583e-01 -    1.79    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  53 - 100% - 9.6159e-01 - 7.8517e-01 - 5.9802e-01 - 2.6342e-01 - 1.2157e-01 - 1.4185e-01 -   13.54    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  53 - 100% - 7.5781e-01 -    1.74    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  54 - 100% - 9.5549e-01 - 7.8672e-01 - 6.0074e-01 - 2.6863e-01 - 1.3322e-01 - 1.3541e-01 -   13.57    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  54 - 100% - 7.6830e-01 -    1.80    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  55 - 100% - 9.5381e-01 - 7.8406e-01 - 5.9695e-01 - 2.7295e-01 - 1.3605e-01 - 1.3689e-01 -   13.74    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  55 - 100% - 7.5366e-01 -    1.78    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  56 - 100% - 9.5686e-01 - 7.8506e-01 - 6.0013e-01 - 2.5944e-01 - 1.2740e-01 - 1.3203e-01 -   13.66    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  56 - 100% - 7.6286e-01 -    1.74    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  57 - 100% - 9.6463e-01 - 7.8550e-01 - 6.0821e-01 - 2.4923e-01 - 1.0908e-01 - 1.4015e-01 -   13.65    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  57 - 100% - 7.6256e-01 -    1.73    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  58 - 100% - 9.6235e-01 - 7.8800e-01 - 6.1074e-01 - 2.5638e-01 - 1.1624e-01 - 1.4014e-01 -   13.98    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  58 - 100% - 7.5900e-01 -    1.77    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  59 - 100% - 9.6479e-01 - 7.9183e-01 - 6.1191e-01 - 2.4492e-01 - 1.0954e-01 - 1.3538e-01 -   14.06    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  59 - 100% - 7.6543e-01 -    1.85    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  60 - 100% - 9.6128e-01 - 7.9022e-01 - 6.1313e-01 - 2.5568e-01 - 1.1362e-01 - 1.4205e-01 -   13.99    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  60 - 100% - 7.7235e-01 -    1.79    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  61 - 100% - 9.6631e-01 - 7.9543e-01 - 6.2064e-01 - 2.3560e-01 - 1.0104e-01 - 1.3456e-01 -   13.97    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  61 - 100% - 7.6335e-01 -    1.81    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  62 - 100% - 9.6555e-01 - 7.9270e-01 - 6.1912e-01 - 2.4109e-01 - 1.0267e-01 - 1.3843e-01 -   14.03    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  62 - 100% - 7.6276e-01 -    1.76    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  63 - 100% - 9.6555e-01 - 7.9606e-01 - 6.2230e-01 - 2.4220e-01 - 1.0472e-01 - 1.3747e-01 -   13.64    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  63 - 100% - 7.5791e-01 -    1.74    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  64 - 100% - 9.6936e-01 - 7.9911e-01 - 6.2199e-01 - 2.2974e-01 - 9.7879e-02 - 1.3186e-01 -   13.56    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  64 - 100% - 7.7423e-01 -    1.76    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  65 - 100% - 9.6479e-01 - 7.9684e-01 - 6.2668e-01 - 2.3552e-01 - 1.0229e-01 - 1.3324e-01 -   13.95    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  65 - 100% - 7.6206e-01 -    1.89    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  66 - 100% - 9.7012e-01 - 7.9656e-01 - 6.2099e-01 - 2.3419e-01 - 9.7729e-02 - 1.3646e-01 -   13.56    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  66 - 100% - 7.6543e-01 -    1.81    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  67 - 100% - 9.7317e-01 - 8.0017e-01 - 6.3484e-01 - 2.2277e-01 - 8.7366e-02 - 1.3541e-01 -   14.19    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  67 - 100% - 7.6750e-01 -    1.82    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  68 - 100% - 9.7393e-01 - 7.9813e-01 - 6.3269e-01 - 2.2185e-01 - 8.4734e-02 - 1.3712e-01 -   13.53    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  68 - 100% - 7.7215e-01 -    1.81    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  69 - 100% - 9.7119e-01 - 8.0192e-01 - 6.3632e-01 - 2.1588e-01 - 8.2673e-02 - 1.3320e-01 -   13.85    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  69 - 100% - 7.7077e-01 -    1.85    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  70 - 100% - 9.7210e-01 - 8.0142e-01 - 6.3920e-01 - 2.1716e-01 - 8.1131e-02 - 1.3603e-01 -   14.02    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  70 - 100% - 7.7166e-01 -    1.78    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  71 - 100% - 9.7363e-01 - 8.0054e-01 - 6.3907e-01 - 2.2405e-01 - 8.6788e-02 - 1.3726e-01 -   13.78    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  71 - 100% - 7.7275e-01 -    1.79    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  72 - 100% - 9.7332e-01 - 7.9841e-01 - 6.3478e-01 - 2.2373e-01 - 8.5929e-02 - 1.3780e-01 -   13.64    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  72 - 100% - 7.6790e-01 -    1.81    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  73 - 100% - 9.6997e-01 - 8.0172e-01 - 6.3500e-01 - 2.2877e-01 - 9.0801e-02 - 1.3797e-01 -   13.79    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  73 - 100% - 7.8214e-01 -    1.82    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  74 - 100% - 9.7241e-01 - 8.0547e-01 - 6.3785e-01 - 2.1604e-01 - 8.4261e-02 - 1.3178e-01 -   13.65    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  74 - 100% - 7.7423e-01 -    1.79    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  75 - 100% - 9.7424e-01 - 8.0516e-01 - 6.3469e-01 - 2.1330e-01 - 8.1376e-02 - 1.3192e-01 -   13.89    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  75 - 100% - 7.7650e-01 -    1.83    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  76 - 100% - 9.7881e-01 - 8.0849e-01 - 6.4778e-01 - 2.0201e-01 - 6.7084e-02 - 1.3492e-01 -   14.11    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  76 - 100% - 7.8145e-01 -    1.86    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  77 - 100% - 9.7774e-01 - 8.0573e-01 - 6.4989e-01 - 2.0972e-01 - 7.4496e-02 - 1.3522e-01 -   13.75    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  77 - 100% - 7.8115e-01 -    1.77    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  78 - 100% - 9.7713e-01 - 8.0647e-01 - 6.4527e-01 - 2.0896e-01 - 7.1577e-02 - 1.3739e-01 -   13.57    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  78 - 100% - 7.7522e-01 -    1.73    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  79 - 100% - 9.8110e-01 - 8.1143e-01 - 6.5418e-01 - 1.9082e-01 - 6.2259e-02 - 1.2856e-01 -   13.72    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  79 - 100% - 7.8590e-01 -    1.80    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  80 - 100% - 9.7759e-01 - 8.0945e-01 - 6.5529e-01 - 2.0223e-01 - 6.7017e-02 - 1.3521e-01 -   13.72    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  80 - 100% - 7.7749e-01 -    1.78    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  81 - 100% - 9.7500e-01 - 8.0856e-01 - 6.4676e-01 - 2.1203e-01 - 7.7994e-02 - 1.3403e-01 -   13.55    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  81 - 100% - 7.7650e-01 -    1.79    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  82 - 100% - 9.8323e-01 - 8.1692e-01 - 6.5849e-01 - 1.8449e-01 - 5.8705e-02 - 1.2579e-01 -   13.64    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  82 - 100% - 7.7987e-01 -    1.75    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  83 - 100% - 9.7912e-01 - 8.1172e-01 - 6.6174e-01 - 1.9741e-01 - 6.3763e-02 - 1.3364e-01 -   13.81    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  83 - 100% - 7.8758e-01 -    1.85    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  84 - 100% - 9.7652e-01 - 8.1278e-01 - 6.5947e-01 - 2.0135e-01 - 6.8494e-02 - 1.3285e-01 -   14.12    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  84 - 100% - 7.8125e-01 -    1.88    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  85 - 100% - 9.7912e-01 - 8.1185e-01 - 6.5775e-01 - 1.9698e-01 - 6.5899e-02 - 1.3108e-01 -   13.69    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  85 - 100% - 7.8412e-01 -    1.76    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  86 - 100% - 9.8521e-01 - 8.1816e-01 - 6.6938e-01 - 1.7626e-01 - 4.8295e-02 - 1.2796e-01 -   13.59    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  86 - 100% - 7.8234e-01 -    1.79    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  87 - 100% - 9.8125e-01 - 8.1714e-01 - 6.6860e-01 - 1.9779e-01 - 6.0006e-02 - 1.3779e-01 -   14.17    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  87 - 100% - 7.7739e-01 -    1.78    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  88 - 100% - 9.8308e-01 - 8.1518e-01 - 6.6368e-01 - 1.9239e-01 - 5.8419e-02 - 1.3397e-01 -   13.74    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  88 - 100% - 7.8066e-01 -    1.79    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  89 - 100% - 9.7561e-01 - 8.1220e-01 - 6.6135e-01 - 2.0083e-01 - 7.1477e-02 - 1.2935e-01 -   13.66    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  89 - 100% - 7.8313e-01 -    1.73    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  90 - 100% - 9.8216e-01 - 8.1736e-01 - 6.6527e-01 - 1.8704e-01 - 5.5547e-02 - 1.3149e-01 -   13.79    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  90 - 100% - 7.8817e-01 -    1.81    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  91 - 100% - 9.8247e-01 - 8.2232e-01 - 6.7254e-01 - 1.8521e-01 - 5.6471e-02 - 1.2874e-01 -   13.91    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  91 - 100% - 7.9173e-01 -    1.84    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  92 - 100% - 9.8552e-01 - 8.2119e-01 - 6.7844e-01 - 1.7659e-01 - 4.6689e-02 - 1.2990e-01 -   13.43    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  92 - 100% - 7.9213e-01 -    1.76    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  93 - 100% - 9.8232e-01 - 8.2149e-01 - 6.7082e-01 - 1.7863e-01 - 4.9255e-02 - 1.2938e-01 -   13.57    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  93 - 100% - 7.8946e-01 -    1.77    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  94 - 100% - 9.8079e-01 - 8.2108e-01 - 6.7241e-01 - 1.8805e-01 - 5.9610e-02 - 1.2844e-01 -   13.52    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  94 - 100% - 7.8461e-01 -    1.75    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  95 - 100% - 9.8628e-01 - 8.2210e-01 - 6.7239e-01 - 1.7429e-01 - 4.6228e-02 - 1.2806e-01 -   13.59    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  95 - 100% - 7.9193e-01 -    1.80    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  96 - 100% - 9.8399e-01 - 8.2223e-01 - 6.7903e-01 - 1.7889e-01 - 5.0876e-02 - 1.2801e-01 -   13.49    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  96 - 100% - 7.8857e-01 -    1.75    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  97 - 100% - 9.8247e-01 - 8.2402e-01 - 6.8160e-01 - 1.8260e-01 - 5.3794e-02 - 1.2881e-01 -   13.67    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  97 - 100% - 7.9272e-01 -    1.79    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  98 - 100% - 9.8476e-01 - 8.2311e-01 - 6.8097e-01 - 1.7747e-01 - 4.8284e-02 - 1.2919e-01 -   13.51    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  98 - 100% - 7.9608e-01 -    1.78    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch  99 - 100% - 9.8887e-01 - 8.2857e-01 - 6.8645e-01 - 1.7210e-01 - 4.2476e-02 - 1.2962e-01 -   13.48    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  99 - 100% - 7.8214e-01 -    1.78    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 100 - 100% - 9.8537e-01 - 8.2539e-01 - 6.8064e-01 - 1.7322e-01 - 4.7937e-02 - 1.2529e-01 -   13.47    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 100 - 100% - 7.9430e-01 -    1.76    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 101 - 100% - 9.8902e-01 - 8.2437e-01 - 6.8393e-01 - 1.7526e-01 - 4.4287e-02 - 1.3098e-01 -   13.56    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 101 - 100% - 7.9223e-01 -    1.75    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 102 - 100% - 9.8186e-01 - 8.2744e-01 - 6.7964e-01 - 1.7721e-01 - 5.2682e-02 - 1.2453e-01 -   13.64    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 102 - 100% - 7.9183e-01 -    1.82    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 103 - 100% - 9.8750e-01 - 8.3027e-01 - 6.8818e-01 - 1.6537e-01 - 3.9133e-02 - 1.2623e-01 -   13.59    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 103 - 100% - 7.9084e-01 -    1.77    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 104 - 100% - 9.8521e-01 - 8.2805e-01 - 6.8798e-01 - 1.7546e-01 - 4.8412e-02 - 1.2705e-01 -   13.33    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 104 - 100% - 7.8689e-01 -    1.77    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 105 - 100% - 9.8735e-01 - 8.2718e-01 - 6.8478e-01 - 1.7255e-01 - 4.3207e-02 - 1.2934e-01 -   13.57    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 105 - 100% - 7.9500e-01 -    1.77    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 106 - 100% - 9.8537e-01 - 8.2707e-01 - 6.8887e-01 - 1.7388e-01 - 4.5229e-02 - 1.2865e-01 -   13.54    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 106 - 100% - 7.9707e-01 -    1.75    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 107 - 100% - 9.9055e-01 - 8.3036e-01 - 6.9656e-01 - 1.6584e-01 - 3.5940e-02 - 1.2990e-01 -   13.53    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 107 - 100% - 7.9638e-01 -    1.74    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 108 - 100% - 9.8750e-01 - 8.3066e-01 - 6.9403e-01 - 1.6414e-01 - 4.1522e-02 - 1.2262e-01 -   13.51    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 108 - 100% - 7.9450e-01 -    1.80    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 109 - 100% - 9.8796e-01 - 8.3384e-01 - 6.9830e-01 - 1.6387e-01 - 3.6530e-02 - 1.2734e-01 -   13.83    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 109 - 100% - 7.8422e-01 -    1.77    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 110 - 100% - 9.8765e-01 - 8.3175e-01 - 6.8961e-01 - 1.6189e-01 - 3.9906e-02 - 1.2199e-01 -   14.09    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 110 - 100% - 7.9173e-01 -    1.78    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 111 - 100% - 9.8872e-01 - 8.3175e-01 - 6.9623e-01 - 1.6050e-01 - 3.4282e-02 - 1.2622e-01 -   13.80    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 111 - 100% - 7.9173e-01 -    1.79    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 112 - 100% - 9.8765e-01 - 8.3055e-01 - 6.9286e-01 - 1.6986e-01 - 4.1564e-02 - 1.2830e-01 -   13.71    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 112 - 100% - 7.9480e-01 -    1.77    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 113 - 100% - 9.8994e-01 - 8.3635e-01 - 6.9743e-01 - 1.5308e-01 - 3.1471e-02 - 1.2161e-01 -   14.13    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 113 - 100% - 7.9144e-01 -    1.81    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 114 - 100% - 9.8933e-01 - 8.3291e-01 - 6.9930e-01 - 1.6292e-01 - 3.8346e-02 - 1.2457e-01 -   13.70    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 114 - 100% - 7.9608e-01 -    1.75    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 115 - 100% - 9.8979e-01 - 8.3571e-01 - 7.0318e-01 - 1.6156e-01 - 3.5821e-02 - 1.2574e-01 -   13.63    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 115 - 100% - 7.9490e-01 -    1.74    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 116 - 100% - 9.8994e-01 - 8.3188e-01 - 7.0342e-01 - 1.5508e-01 - 3.0674e-02 - 1.2440e-01 -   13.66    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 116 - 100% - 7.9866e-01 -    1.74    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 117 - 100% - 9.9040e-01 - 8.3944e-01 - 7.0621e-01 - 1.5064e-01 - 2.9467e-02 - 1.2117e-01 -   14.28    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 117 - 100% - 7.9796e-01 -    1.83    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 118 - 100% - 9.8902e-01 - 8.3504e-01 - 7.0329e-01 - 1.6153e-01 - 3.7902e-02 - 1.2363e-01 -   13.93    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 118 - 100% - 7.9846e-01 -    1.77    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 119 - 100% - 9.8887e-01 - 8.3785e-01 - 7.0268e-01 - 1.5995e-01 - 3.8623e-02 - 1.2133e-01 -   13.87    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 119 - 100% - 7.9628e-01 -    1.83    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 120 - 100% - 9.9116e-01 - 8.3900e-01 - 7.0762e-01 - 1.5459e-01 - 3.4802e-02 - 1.1979e-01 -   13.81    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 120 - 100% - 7.9668e-01 -    1.76    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 121 - 100% - 9.9238e-01 - 8.3961e-01 - 7.0684e-01 - 1.5571e-01 - 3.0446e-02 - 1.2527e-01 -   13.70    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 121 - 100% - 7.9470e-01 -    1.75    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 122 - 100% - 9.9329e-01 - 8.4042e-01 - 7.1616e-01 - 1.4778e-01 - 2.6182e-02 - 1.2160e-01 -   13.55    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 122 - 100% - 8.0133e-01 -    1.78    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 123 - 100% - 9.9131e-01 - 8.4003e-01 - 7.0751e-01 - 1.5162e-01 - 2.9501e-02 - 1.2212e-01 -   13.69    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 123 - 100% - 7.9648e-01 -    1.75    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 124 - 100% - 9.8841e-01 - 8.3848e-01 - 7.0655e-01 - 1.5690e-01 - 3.5453e-02 - 1.2145e-01 -   13.56    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 124 - 100% - 7.9490e-01 -    1.80    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 125 - 100% - 9.9223e-01 - 8.3878e-01 - 7.1344e-01 - 1.4959e-01 - 2.6981e-02 - 1.2261e-01 -   13.66    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 125 - 100% - 8.0479e-01 -    1.79    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 126 - 100% - 9.9314e-01 - 8.4255e-01 - 7.1625e-01 - 1.4776e-01 - 2.8034e-02 - 1.1972e-01 -   13.64    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 126 - 100% - 8.0419e-01 -    1.77    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 127 - 100% - 9.9131e-01 - 8.4373e-01 - 7.1535e-01 - 1.4433e-01 - 2.7905e-02 - 1.1642e-01 -   13.83    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 127 - 100% - 8.0053e-01 -    1.83    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 128 - 100% - 9.9299e-01 - 8.4658e-01 - 7.2356e-01 - 1.4639e-01 - 2.6201e-02 - 1.2019e-01 -   13.85    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 128 - 100% - 7.9925e-01 -    1.81    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 129 - 100% - 9.9238e-01 - 8.4168e-01 - 7.1701e-01 - 1.5155e-01 - 2.8934e-02 - 1.2262e-01 -   13.97    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 129 - 100% - 7.9341e-01 -    1.80    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 130 - 100% - 9.9314e-01 - 8.4615e-01 - 7.1588e-01 - 1.4412e-01 - 2.6936e-02 - 1.1718e-01 -   14.49    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 130 - 100% - 8.0231e-01 -    1.82    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 131 - 100% - 9.9207e-01 - 8.4737e-01 - 7.1934e-01 - 1.4407e-01 - 2.5525e-02 - 1.1855e-01 -   14.14    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 131 - 100% - 8.0320e-01 -    1.82    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 132 - 100% - 9.9177e-01 - 8.4625e-01 - 7.1980e-01 - 1.4214e-01 - 2.5432e-02 - 1.1670e-01 -   14.25    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 132 - 100% - 8.0409e-01 -    1.79    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 133 - 100% - 9.9543e-01 - 8.4717e-01 - 7.2311e-01 - 1.4185e-01 - 2.0391e-02 - 1.2146e-01 -   14.05    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 133 - 100% - 8.0241e-01 -    1.85    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 134 - 100% - 9.9146e-01 - 8.4519e-01 - 7.2165e-01 - 1.5068e-01 - 2.8070e-02 - 1.2261e-01 -   13.72    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 134 - 100% - 8.0340e-01 -    1.83    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 135 - 100% - 9.9405e-01 - 8.4965e-01 - 7.2459e-01 - 1.3838e-01 - 2.2573e-02 - 1.1581e-01 -   13.79    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 135 - 100% - 7.9806e-01 -    1.80    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 136 - 100% - 9.9375e-01 - 8.4954e-01 - 7.2500e-01 - 1.3951e-01 - 2.3942e-02 - 1.1557e-01 -   14.18    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 136 - 100% - 8.0202e-01 -    1.83    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 137 - 100% - 9.9299e-01 - 8.4858e-01 - 7.2350e-01 - 1.3895e-01 - 2.5777e-02 - 1.1317e-01 -   13.83    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 137 - 100% - 8.0202e-01 -    1.74    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 138 - 100% - 9.9421e-01 - 8.5098e-01 - 7.3182e-01 - 1.3823e-01 - 2.1100e-02 - 1.1713e-01 -   13.66    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 138 - 100% - 8.0568e-01 -    1.80    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 139 - 100% - 9.9360e-01 - 8.4974e-01 - 7.2689e-01 - 1.3948e-01 - 2.2868e-02 - 1.1661e-01 -   14.24    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 139 - 100% - 8.0983e-01 -    1.84    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 140 - 100% - 9.9588e-01 - 8.5096e-01 - 7.3018e-01 - 1.3522e-01 - 1.8675e-02 - 1.1654e-01 -   14.00    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 140 - 100% - 8.0320e-01 -    1.81    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 141 - 100% - 9.9116e-01 - 8.5020e-01 - 7.2818e-01 - 1.4227e-01 - 2.4089e-02 - 1.1818e-01 -   14.17    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 141 - 100% - 8.0291e-01 -    1.77    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 142 - 100% - 9.9345e-01 - 8.5122e-01 - 7.3081e-01 - 1.3917e-01 - 2.2452e-02 - 1.1672e-01 -   13.96    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 142 - 100% - 8.0607e-01 -    1.83    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 143 - 100% - 9.9451e-01 - 8.5226e-01 - 7.3171e-01 - 1.3543e-01 - 1.8898e-02 - 1.1653e-01 -   13.78    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 143 - 100% - 8.0973e-01 -    1.82    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 144 - 100% - 9.9588e-01 - 8.5207e-01 - 7.3478e-01 - 1.3121e-01 - 1.6617e-02 - 1.1459e-01 -   14.21    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 144 - 100% - 8.0785e-01 -    1.82    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 145 - 100% - 9.9604e-01 - 8.5721e-01 - 7.3889e-01 - 1.3034e-01 - 1.4651e-02 - 1.1569e-01 -   13.58    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 145 - 100% - 8.0597e-01 -    1.77    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 146 - 100% - 9.9238e-01 - 8.5322e-01 - 7.3230e-01 - 1.3816e-01 - 2.4218e-02 - 1.1394e-01 -   13.57    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 146 - 100% - 8.0212e-01 -    1.79    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 147 - 100% - 9.9238e-01 - 8.5486e-01 - 7.3038e-01 - 1.3823e-01 - 2.3209e-02 - 1.1502e-01 -   13.63    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 147 - 100% - 8.0291e-01 -    1.81    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 148 - 100% - 9.9543e-01 - 8.5233e-01 - 7.3055e-01 - 1.3282e-01 - 1.9039e-02 - 1.1378e-01 -   13.79    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 148 - 100% - 8.0914e-01 -    1.77    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 149 - 100% - 9.9421e-01 - 8.5566e-01 - 7.3349e-01 - 1.3691e-01 - 2.0218e-02 - 1.1669e-01 -   13.77    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 149 - 100% - 8.0251e-01 -    1.76    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 150 - 100% - 9.9573e-01 - 8.5760e-01 - 7.3966e-01 - 1.2927e-01 - 1.7912e-02 - 1.1136e-01 -   13.54    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 150 - 100% - 8.0538e-01 -    1.78    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 151 - 100% - 9.9604e-01 - 8.5595e-01 - 7.3565e-01 - 1.3122e-01 - 1.5307e-02 - 1.1592e-01 -   13.65    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 151 - 100% - 8.0587e-01 -    1.73    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 152 - 100% - 9.9390e-01 - 8.5723e-01 - 7.3672e-01 - 1.3348e-01 - 1.9186e-02 - 1.1429e-01 -   13.58    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 152 - 100% - 8.0261e-01 -    1.76    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 153 - 100% - 9.9588e-01 - 8.5740e-01 - 7.4201e-01 - 1.3102e-01 - 1.6998e-02 - 1.1402e-01 -   14.24    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 153 - 100% - 8.1141e-01 -    1.91    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 154 - 100% - 9.9573e-01 - 8.6139e-01 - 7.4179e-01 - 1.2493e-01 - 1.5608e-02 - 1.0933e-01 -   14.73    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 154 - 100% - 8.0953e-01 -    1.98    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 155 - 100% - 9.9543e-01 - 8.5923e-01 - 7.4018e-01 - 1.2894e-01 - 1.6314e-02 - 1.1263e-01 -   13.70    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 155 - 100% - 8.0756e-01 -    1.80    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 156 - 100% - 9.9726e-01 - 8.5960e-01 - 7.4338e-01 - 1.2321e-01 - 1.3152e-02 - 1.1005e-01 -   13.96    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 156 - 100% - 8.0568e-01 -    1.78    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 157 - 100% - 9.9588e-01 - 8.5928e-01 - 7.4364e-01 - 1.2733e-01 - 1.5929e-02 - 1.1140e-01 -   13.47    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 157 - 100% - 8.1468e-01 -    1.79    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 158 - 100% - 9.9573e-01 - 8.5834e-01 - 7.4569e-01 - 1.2508e-01 - 1.4112e-02 - 1.1097e-01 -   13.57    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 158 - 100% - 8.0934e-01 -    1.77    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 159 - 100% - 9.9619e-01 - 8.6122e-01 - 7.4673e-01 - 1.2615e-01 - 1.3997e-02 - 1.1215e-01 -   13.72    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 159 - 100% - 8.0429e-01 -    1.82    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 160 - 100% - 9.9558e-01 - 8.5910e-01 - 7.4312e-01 - 1.2981e-01 - 1.6108e-02 - 1.1370e-01 -   13.50    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 160 - 100% - 8.0815e-01 -    1.76    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 161 - 100% - 9.9710e-01 - 8.6363e-01 - 7.5128e-01 - 1.2351e-01 - 1.4450e-02 - 1.0906e-01 -   13.57    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 161 - 100% - 8.1359e-01 -    1.76    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 162 - 100% - 9.9588e-01 - 8.6178e-01 - 7.4645e-01 - 1.2504e-01 - 1.6792e-02 - 1.0825e-01 -   13.58    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 162 - 100% - 8.1112e-01 -    1.79    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 163 - 100% - 9.9649e-01 - 8.6187e-01 - 7.5100e-01 - 1.2417e-01 - 1.4688e-02 - 1.0948e-01 -   13.54    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 163 - 100% - 8.1082e-01 -    1.78    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 164 - 100% - 9.9634e-01 - 8.6163e-01 - 7.4678e-01 - 1.2212e-01 - 1.4237e-02 - 1.0789e-01 -   13.77    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 164 - 100% - 8.1171e-01 -    1.84    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 165 - 100% - 9.9771e-01 - 8.6577e-01 - 7.5841e-01 - 1.1852e-01 - 1.1010e-02 - 1.0751e-01 -   13.96    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 165 - 100% - 8.0498e-01 -    1.92    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 166 - 100% - 9.9649e-01 - 8.6407e-01 - 7.5017e-01 - 1.2168e-01 - 1.2935e-02 - 1.0874e-01 -   14.18    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 166 - 100% - 8.1408e-01 -    1.82    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 167 - 100% - 9.9741e-01 - 8.6505e-01 - 7.5244e-01 - 1.2258e-01 - 1.3302e-02 - 1.0928e-01 -   13.96    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 167 - 100% - 8.1537e-01 -    1.85    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 168 - 100% - 9.9512e-01 - 8.6814e-01 - 7.5070e-01 - 1.1788e-01 - 1.5283e-02 - 1.0260e-01 -   13.99    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 168 - 100% - 8.1191e-01 -    1.77    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 169 - 100% - 9.9665e-01 - 8.6821e-01 - 7.5507e-01 - 1.1891e-01 - 1.3154e-02 - 1.0576e-01 -   14.23    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 169 - 100% - 8.1121e-01 -    1.78    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 170 - 100% - 9.9558e-01 - 8.6335e-01 - 7.5301e-01 - 1.2552e-01 - 1.4072e-02 - 1.1145e-01 -   13.52    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 170 - 100% - 8.1141e-01 -    1.75    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 171 - 100% - 9.9710e-01 - 8.6605e-01 - 7.5420e-01 - 1.1802e-01 - 1.1507e-02 - 1.0651e-01 -   13.51    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 171 - 100% - 8.1290e-01 -    1.79    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 172 - 100% - 9.9756e-01 - 8.6840e-01 - 7.5544e-01 - 1.1778e-01 - 9.9906e-03 - 1.0779e-01 -   13.42    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 172 - 100% - 8.1112e-01 -    1.75    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 173 - 100% - 9.9695e-01 - 8.6729e-01 - 7.5965e-01 - 1.2099e-01 - 1.2002e-02 - 1.0899e-01 -   13.55    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 173 - 100% - 8.1369e-01 -    1.77    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 174 - 100% - 9.9665e-01 - 8.6984e-01 - 7.5902e-01 - 1.1977e-01 - 1.1677e-02 - 1.0809e-01 -   13.81    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 174 - 100% - 8.1557e-01 -    1.85    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 175 - 100% - 9.9665e-01 - 8.6590e-01 - 7.5952e-01 - 1.2021e-01 - 1.2244e-02 - 1.0797e-01 -   14.99    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 175 - 100% - 8.1537e-01 -    1.78    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 176 - 100% - 9.9863e-01 - 8.6803e-01 - 7.5605e-01 - 1.1390e-01 - 7.7177e-03 - 1.0619e-01 -   13.44    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 176 - 100% - 8.1685e-01 -    1.78    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 177 - 100% - 9.9634e-01 - 8.6845e-01 - 7.5499e-01 - 1.1990e-01 - 1.3376e-02 - 1.0652e-01 -   13.54    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 177 - 100% - 8.1893e-01 -    1.85    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 178 - 100% - 9.9741e-01 - 8.6779e-01 - 7.5867e-01 - 1.1317e-01 - 1.0938e-02 - 1.0224e-01 -   14.03    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 178 - 100% - 8.1369e-01 -    1.84    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 179 - 100% - 9.9726e-01 - 8.7012e-01 - 7.6041e-01 - 1.1239e-01 - 9.5311e-03 - 1.0286e-01 -   13.77    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 179 - 100% - 8.1477e-01 -    1.81    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 180 - 100% - 9.9802e-01 - 8.7352e-01 - 7.6755e-01 - 1.1214e-01 - 8.2797e-03 - 1.0387e-01 -   13.97    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 180 - 100% - 8.1527e-01 -    1.77    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 181 - 100% - 9.9695e-01 - 8.7027e-01 - 7.6572e-01 - 1.1997e-01 - 1.1516e-02 - 1.0846e-01 -   13.98    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 181 - 100% - 8.1359e-01 -    1.75    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 182 - 100% - 9.9817e-01 - 8.7208e-01 - 7.6122e-01 - 1.1402e-01 - 9.9701e-03 - 1.0405e-01 -   13.81    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 182 - 100% - 8.1626e-01 -    1.79    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 183 - 100% - 9.9695e-01 - 8.7297e-01 - 7.6320e-01 - 1.1231e-01 - 1.1176e-02 - 1.0113e-01 -   13.57    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 183 - 100% - 8.1843e-01 -    1.75    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 184 - 100% - 9.9665e-01 - 8.7038e-01 - 7.5947e-01 - 1.1277e-01 - 1.2550e-02 - 1.0022e-01 -   13.58    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 184 - 100% - 8.1428e-01 -    1.76    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 185 - 100% - 9.9802e-01 - 8.7502e-01 - 7.6553e-01 - 1.0973e-01 - 8.5485e-03 - 1.0118e-01 -   13.76    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 185 - 100% - 8.1863e-01 -    1.77    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 186 - 100% - 9.9802e-01 - 8.7574e-01 - 7.6770e-01 - 1.0833e-01 - 8.7269e-03 - 9.9604e-02 -   13.71    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 186 - 100% - 8.1655e-01 -    1.76    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 187 - 100% - 9.9726e-01 - 8.6936e-01 - 7.6291e-01 - 1.1596e-01 - 1.0670e-02 - 1.0529e-01 -   13.52    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 187 - 100% - 8.1646e-01 -    1.75    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 188 - 100% - 9.9848e-01 - 8.7877e-01 - 7.6873e-01 - 1.0813e-01 - 6.4805e-03 - 1.0165e-01 -   13.56    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 188 - 100% - 8.2189e-01 -    1.79    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 189 - 100% - 9.9756e-01 - 8.7535e-01 - 7.6509e-01 - 1.1009e-01 - 9.9731e-03 - 1.0012e-01 -   13.72    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 189 - 100% - 8.1685e-01 -    1.75    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 190 - 100% - 9.9726e-01 - 8.7633e-01 - 7.6886e-01 - 1.1055e-01 - 9.3969e-03 - 1.0115e-01 -   13.87    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 190 - 100% - 8.1487e-01 -    1.76    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 191 - 100% - 9.9832e-01 - 8.7868e-01 - 7.7152e-01 - 1.0740e-01 - 8.5180e-03 - 9.8878e-02 -   13.85    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 191 - 100% - 8.2199e-01 -    1.79    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 192 - 100% - 9.9924e-01 - 8.7772e-01 - 7.7480e-01 - 1.0462e-01 - 6.0291e-03 - 9.8593e-02 -   13.68    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 192 - 100% - 8.1468e-01 -    1.80    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 193 - 100% - 9.9878e-01 - 8.7777e-01 - 7.7354e-01 - 1.0459e-01 - 5.9811e-03 - 9.8606e-02 -   14.23    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 193 - 100% - 8.1725e-01 -    1.76    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 194 - 100% - 9.9878e-01 - 8.7615e-01 - 7.7430e-01 - 1.0904e-01 - 5.5310e-03 - 1.0351e-01 -   13.58    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 194 - 100% - 8.1794e-01 -    1.76    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 195 - 100% - 9.9802e-01 - 8.7831e-01 - 7.7637e-01 - 1.0891e-01 - 8.7651e-03 - 1.0014e-01 -   13.92    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 195 - 100% - 8.1992e-01 -    1.83    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 196 - 100% - 9.9848e-01 - 8.8016e-01 - 7.7402e-01 - 1.0178e-01 - 6.2158e-03 - 9.5565e-02 -   13.55    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 196 - 100% - 8.2041e-01 -    1.80    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 197 - 100% - 9.9878e-01 - 8.7779e-01 - 7.7511e-01 - 1.0613e-01 - 6.2609e-03 - 9.9866e-02 -   13.78    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 197 - 100% - 8.1824e-01 -    1.85    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 198 - 100% - 9.9863e-01 - 8.7733e-01 - 7.7803e-01 - 1.0798e-01 - 6.2687e-03 - 1.0171e-01 -   13.88    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 198 - 100% - 8.1764e-01 -    1.82    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 199 - 100% - 9.9893e-01 - 8.8034e-01 - 7.7870e-01 - 1.0225e-01 - 5.7902e-03 - 9.6461e-02 -   13.97    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 199 - 100% - 8.2180e-01 -    1.79    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -  took (s)  -\n",
      "- Epoch 200 - 100% - 9.9939e-01 - 8.8090e-01 - 7.8182e-01 - 1.0526e-01 - 5.6982e-03 - 9.9565e-02 -   13.79    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 200 - 100% - 8.1596e-01 -    1.76    -\r\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(nb_epochs):\n",
    "\ttrain(epoch)\n",
    "\twith torch.no_grad():\n",
    "\t\tval(epoch)\n",
    "\tsched.step()\n",
    "\n",
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}