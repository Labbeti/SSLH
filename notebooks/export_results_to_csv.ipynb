{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "tested-commissioner",
   "metadata": {},
   "source": [
    "# Export results to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sweet-adoption",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import os.path as osp\n",
    "import re\n",
    "\n",
    "from typing import Any, Iterable, Union\n",
    "\n",
    "import pandas as pd\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-contractor",
   "metadata": {},
   "source": [
    "### Get logdirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "finished-specification",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_logdirs(log_root: str, maxdeep: int) -> list[str]:\n",
    "\tdef list_files_rec(path: str, deep: int) -> list[tuple[str, int]]:\n",
    "\t\tif osp.isdir(path):\n",
    "\t\t\tif maxdeep != -1 and deep >= maxdeep:\n",
    "\t\t\t\treturn [(path, deep)]\n",
    "\t\t\telse:\n",
    "\t\t\t\treturn [(subpath, subdeep) for name in os.listdir(path) for subpath, subdeep in list_files_rec(osp.join(path, name), deep+1)]\n",
    "\t\telse:\n",
    "\t\t\treturn []\n",
    "\tfiles_with_deep = list_files_rec(log_root, 0)\n",
    "\treturn [path for path, _ in files_with_deep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adopted-birthday",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_logdirs(\n",
    "    logdirs: Iterable[str],\n",
    "    logdirs_include_patterns: Union[str, Iterable[str]]\n",
    ") -> list[str]:\n",
    "    if isinstance(logdirs_include_patterns, str):\n",
    "        logdirs_include_patterns = [logdirs_include_patterns]\n",
    "    logdirs_include_patterns = list(map(re.compile, logdirs_include_patterns))  # type: ignore\n",
    "    included_logdirs = [\n",
    "        logdir\n",
    "        for logdir in logdirs\n",
    "        if any(re.match(pattern, logdir) for pattern in logdirs_include_patterns)\n",
    "    ]\n",
    "    return included_logdirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "anticipated-colonial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_root='/homelocal/labbeti/Desktop/root_aac/OSI_SYNC/root_sslh/SSLH/logs'\n",
      "len(all_logdirs)=433\n",
      "- /homelocal/labbeti/Desktop/root_aac/OSI_SYNC/root_sslh/SSLH/logs/ssl_ubs8k/mean_teacher_mixup/2023-02-02_16-49-59_R20-data_ssl_ubs8k-pl_mean_teacher_mixup-bsizes_128_128--val_fold_6\n",
      "- /homelocal/labbeti/Desktop/root_aac/OSI_SYNC/root_sslh/SSLH/logs/ssl_ubs8k/mean_teacher_mixup/2023-02-02_16-49-58_R20-data_ssl_ubs8k-pl_mean_teacher_mixup-bsizes_128_128--val_fold_5\n",
      "- /homelocal/labbeti/Desktop/root_aac/OSI_SYNC/root_sslh/SSLH/logs/ssl_ubs8k/mean_teacher_mixup/2023-02-02_16-50-02_R20-data_ssl_ubs8k-pl_mean_teacher_mixup-bsizes_128_128--val_fold_8\n",
      "- /homelocal/labbeti/Desktop/root_aac/OSI_SYNC/root_sslh/SSLH/logs/ssl_ubs8k/mean_teacher_mixup/2023-02-02_16-50-04_R20-data_ssl_ubs8k-pl_mean_teacher_mixup-bsizes_128_128--val_fold_10\n",
      "- /homelocal/labbeti/Desktop/root_aac/OSI_SYNC/root_sslh/SSLH/logs/ssl_ubs8k/mean_teacher_mixup/2023-02-02_16-49-57_R20-data_ssl_ubs8k-pl_mean_teacher_mixup-bsizes_128_128--val_fold_4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_root = \"/users/samova/elabbe/root_sslh/SSLH/calmip_logs\"\n",
    "log_root = \"/users/samova/elabbe/root_sslh/SSLH/logs\"\n",
    "log_root = \"/homelocal/labbeti/Desktop/root_aac/OSI_SYNC/root_sslh/SSLH/logs\"\n",
    "all_logdirs = list_logdirs(log_root, 3)\n",
    "print(f\"{log_root=}\")\n",
    "print(f\"{len(all_logdirs)=}\")\n",
    "print(f\"{yaml.dump(all_logdirs[:5], sort_keys=False)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjustable-teach",
   "metadata": {},
   "source": [
    "### Filter logdirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "collective-tuesday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern='.*(R22)-.*'\n",
      "len(logdirs)=4\n"
     ]
    }
   ],
   "source": [
    "pattern = \".*(R22)-.*\"\n",
    "\n",
    "logdirs = filter_logdirs(all_logdirs, pattern)\n",
    "print(f\"{pattern=}\")\n",
    "print(f\"{len(logdirs)=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-circle",
   "metadata": {},
   "source": [
    "### Read results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ambient-radical",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_dict(x) -> dict:\n",
    "\tdef flat_lst(x) -> Any:\n",
    "\t\tif isinstance(x, dict):\n",
    "\t\t\treturn {k: flat_lst(v) for k, v in x.items()}\n",
    "\t\telif isinstance(x, (list, tuple)):\n",
    "\t\t\treturn {i: flat_lst(v) for i, v in enumerate(x)}\t\n",
    "\t\telse:\n",
    "\t\t\treturn x\n",
    "\n",
    "\tx = flat_lst(x)\n",
    "\tx = pd.json_normalize(x, sep=\".\").to_dict(orient='records')[0]\n",
    "\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "alleged-oxford",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hp.tag</th>\n",
       "      <th>met.val_best/acc</th>\n",
       "      <th>hp.data.dm.val_folds.0</th>\n",
       "      <th>met.other/fit_duration_h</th>\n",
       "      <th>met.other/test_duration_h</th>\n",
       "      <th>met.val_best/ce</th>\n",
       "      <th>hp.seed</th>\n",
       "      <th>hp.datetime</th>\n",
       "      <th>hp.debug</th>\n",
       "      <th>hp.epochs</th>\n",
       "      <th>...</th>\n",
       "      <th>hp.strong_aug.2.aug.fill_value</th>\n",
       "      <th>hp.strong_aug.2.aug.p</th>\n",
       "      <th>hp.pl.threshold</th>\n",
       "      <th>hp.criterion</th>\n",
       "      <th>hp.train_aug.0.type</th>\n",
       "      <th>hp.train_aug.0.aug._target_</th>\n",
       "      <th>hp.data.dm.bsize</th>\n",
       "      <th>hp.data.dm.ratio</th>\n",
       "      <th>hp.pl.criterion._target_</th>\n",
       "      <th>hp.pl.criterion.reduction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R22-data_-pl_fixmatch-epochs_10-bsizes_128_128...</td>\n",
       "      <td>0.703971</td>\n",
       "      <td>1</td>\n",
       "      <td>0.498648</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>-0.673017</td>\n",
       "      <td>1234</td>\n",
       "      <td>2023-02-22_15-45-01</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R22-data_-pl_mixmatch-epochs_10-bsizes_128_128...</td>\n",
       "      <td>0.697619</td>\n",
       "      <td>1</td>\n",
       "      <td>0.497031</td>\n",
       "      <td>0.003801</td>\n",
       "      <td>-0.521554</td>\n",
       "      <td>1234</td>\n",
       "      <td>2023-02-22_15-45-00</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R22-data_-pl_supervised-epochs_10-bsize_128-SU...</td>\n",
       "      <td>0.637436</td>\n",
       "      <td>1</td>\n",
       "      <td>0.036640</td>\n",
       "      <td>0.004307</td>\n",
       "      <td>-0.489522</td>\n",
       "      <td>1234</td>\n",
       "      <td>2023-02-22_15-44-57</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CrossEntropyLossVecTargets</td>\n",
       "      <td>spectrogram</td>\n",
       "      <td>torch.nn.Identity</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>sslh.nn.loss.CrossEntropyLossVecTargets</td>\n",
       "      <td>mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R22-data_-pl_supervised-epochs_10-bsize_128-SU...</td>\n",
       "      <td>0.722024</td>\n",
       "      <td>1</td>\n",
       "      <td>0.264120</td>\n",
       "      <td>0.004179</td>\n",
       "      <td>-0.688925</td>\n",
       "      <td>1234</td>\n",
       "      <td>2023-02-22_15-44-59</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CrossEntropyLossVecTargets</td>\n",
       "      <td>spectrogram</td>\n",
       "      <td>torch.nn.Identity</td>\n",
       "      <td>128.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sslh.nn.loss.CrossEntropyLossVecTargets</td>\n",
       "      <td>mean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              hp.tag  met.val_best/acc  \\\n",
       "0  R22-data_-pl_fixmatch-epochs_10-bsizes_128_128...          0.703971   \n",
       "1  R22-data_-pl_mixmatch-epochs_10-bsizes_128_128...          0.697619   \n",
       "2  R22-data_-pl_supervised-epochs_10-bsize_128-SU...          0.637436   \n",
       "3  R22-data_-pl_supervised-epochs_10-bsize_128-SU...          0.722024   \n",
       "\n",
       "   hp.data.dm.val_folds.0  met.other/fit_duration_h  \\\n",
       "0                       1                  0.498648   \n",
       "1                       1                  0.497031   \n",
       "2                       1                  0.036640   \n",
       "3                       1                  0.264120   \n",
       "\n",
       "   met.other/test_duration_h  met.val_best/ce  hp.seed          hp.datetime  \\\n",
       "0                   0.003983        -0.673017     1234  2023-02-22_15-45-01   \n",
       "1                   0.003801        -0.521554     1234  2023-02-22_15-45-00   \n",
       "2                   0.004307        -0.489522     1234  2023-02-22_15-44-57   \n",
       "3                   0.004179        -0.688925     1234  2023-02-22_15-44-59   \n",
       "\n",
       "   hp.debug  hp.epochs  ... hp.strong_aug.2.aug.fill_value  \\\n",
       "0     False         10  ...                          -80.0   \n",
       "1     False         10  ...                            NaN   \n",
       "2     False         10  ...                            NaN   \n",
       "3     False         10  ...                            NaN   \n",
       "\n",
       "   hp.strong_aug.2.aug.p hp.pl.threshold                hp.criterion  \\\n",
       "0                    1.0            0.95                         NaN   \n",
       "1                    NaN             NaN                         NaN   \n",
       "2                    NaN             NaN  CrossEntropyLossVecTargets   \n",
       "3                    NaN             NaN  CrossEntropyLossVecTargets   \n",
       "\n",
       "   hp.train_aug.0.type hp.train_aug.0.aug._target_ hp.data.dm.bsize  \\\n",
       "0                  NaN                         NaN              NaN   \n",
       "1                  NaN                         NaN              NaN   \n",
       "2          spectrogram           torch.nn.Identity            128.0   \n",
       "3          spectrogram           torch.nn.Identity            128.0   \n",
       "\n",
       "  hp.data.dm.ratio                 hp.pl.criterion._target_  \\\n",
       "0              NaN                                      NaN   \n",
       "1              NaN                                      NaN   \n",
       "2              0.1  sslh.nn.loss.CrossEntropyLossVecTargets   \n",
       "3              1.0  sslh.nn.loss.CrossEntropyLossVecTargets   \n",
       "\n",
       "  hp.pl.criterion.reduction  \n",
       "0                       NaN  \n",
       "1                       NaN  \n",
       "2                      mean  \n",
       "3                      mean  \n",
       "\n",
       "[4 rows x 170 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excluded_values = [\".*hp_metric\", \"hp.slurm.output\", \"hp.slurm.error\"]\n",
    "column_order_patterns = [\".*tag\", \"met.*acc\", \".*val_folds\", \"met.*duration\", \"met.*\", \"hp.seed\", \".*\"]\n",
    "line_order = [\"hp.tag\", \"hp.data.dm.val_folds.0\"]\n",
    "\n",
    "results_list = []\n",
    "for logdir in logdirs:\n",
    "\tresults = {}\n",
    "\tskip = False\n",
    "\tfiles = [\n",
    "\t\t(\"met\", \"metrics.yaml\"),\n",
    "\t\t(\"hp\", \"hparams.yaml\"),\n",
    "\t]\n",
    "\t\n",
    "\tfor prefix, fname in files:\n",
    "\t\tfpath = osp.join(logdir, fname)\n",
    "\t\tif not osp.isfile(fpath):\n",
    "\t\t\tprint(f\"Cannot find {fname} in {osp.basename(logdir)}\")\n",
    "\t\t\tskip = True\n",
    "\t\t\tbreak\n",
    "\t\twith open(fpath, \"r\") as file:\n",
    "\t\t\tfile_results = yaml.safe_load(file)\n",
    "\t\t\n",
    "\t\tfile_results = flat_dict(file_results)\n",
    "\t\tfile_results = {\".\".join([prefix, k]): v for k, v in file_results.items()}\n",
    "\t\tfile_results = {\n",
    "\t\t\tk: v for k, v in file_results.items()\n",
    "\t\t\tif not any(re.match(p, k) for p in excluded_values)\n",
    "\t\t}\n",
    "\t\t\n",
    "\t\tresults |= file_results\n",
    "\n",
    "\tif skip:\n",
    "\t\tcontinue\n",
    "\n",
    "\tresults_ordered = {}\n",
    "\tfor p in column_order_patterns:\n",
    "\t\tresults_ordered |= {k: v for k, v in results.items() if k not in results_ordered and re.match(p, k)}\n",
    "\tresults_list.append(results_ordered)\n",
    "\n",
    "df = pd.DataFrame(results_list)\n",
    "df.sort_values([k for k in line_order if k in df.keys()], ascending=True, inplace=True)\n",
    "df.index = list(range(len(df)))\n",
    "df.head(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-piece",
   "metadata": {},
   "source": [
    "### Export to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "upset-annotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_csv(df: pd.DataFrame, fpath: str) -> None:\n",
    "\tlst_dic = df.to_dict(\"records\")\n",
    "\tkeys = list(df.keys())\n",
    "\n",
    "\twith open(fpath, \"w\") as file:\n",
    "\t\twriter = csv.DictWriter(file, fieldnames=keys)\n",
    "\t\twriter.writeheader()\n",
    "\t\twriter.writerows(lst_dic)\n",
    "\tprint(f\"Export {len(df)} results in {fpath=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "antique-subject",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export 4 results in fpath='nb_data/results_sslh.ign.csv'\n"
     ]
    }
   ],
   "source": [
    "export_to_csv(df, \"nb_data/results_sslh.ign.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-typing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_sslh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "be248bc6367c75a6390db6284a951edef2e2fc4b96de412cb2b3f2fca69349aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
