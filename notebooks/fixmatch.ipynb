{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# FixMatch implementation\n",
    "Unofficial pytorch implementation of FixMatch [[paper]](https://arxiv.org/pdf/2001.07685.pdf) on CIFAR-10.\n",
    "\n",
    "## Initialisation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import math\n",
    "import os.path as osp\n",
    "import torch\n",
    "\n",
    "from mlu.datasets.utils import generate_indexes\n",
    "from mlu.datasets.wrappers import NoLabelDataset, ZipDataset\n",
    "from mlu.metrics.categorical import CategoricalAccuracy\n",
    "from mlu.metrics.incremental import IncrementalMean\n",
    "from mlu.nn import OneHot\n",
    "from mlu.nn.utils import get_reduction_from_name\n",
    "from mlu.transforms.image import RandAugment\n",
    "from mlu.utils.misc import reset_seed, get_datetime, get_lr\n",
    "from mlu.utils.printers import ColumnPrinter\n",
    "\n",
    "from torch import Tensor, nn\n",
    "from torch.nn import Module\n",
    "from torch.nn.functional import one_hot\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.dataset import Subset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import RandomHorizontalFlip, RandomChoice, Compose, ToTensor, RandomCrop\n",
    "\n",
    "from typing import Callable, Iterable, Optional, Sized"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "nb_epochs = 300\n",
    "lambda_u = 1.0\n",
    "threshold = 0.95\n",
    "bsize = 64\n",
    "mu = 7\n",
    "nb_labels = 4000\n",
    "lr = 0.03\n",
    "seed = 1234\n",
    "\n",
    "# SGD parameters\n",
    "weight_decay = 0.0005\n",
    "momentum = 0.9  # called \"beta\" in paper\n",
    "nesterov = False\n",
    "\n",
    "reset_seed(seed)\n",
    "\n",
    "dataset_root = osp.join(\"..\", \"datasets\")\n",
    "tensorboard_root = osp.join(\"..\", \"results\", \"tensorboard\")\n",
    "device = torch.device(\"cuda\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "\t\"\"\"3x3 convolution with padding\"\"\"\n",
    "\treturn nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "\t\t\t\t\t padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "\t\"\"\"1x1 convolution\"\"\"\n",
    "\treturn nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "\texpansion = 1\n",
    "\n",
    "\tdef __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "\t\t\t\t base_width=64, dilation=1, norm_layer=None):\n",
    "\t\tsuper(BasicBlock, self).__init__()\n",
    "\n",
    "\t\t# Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "\t\tself.conv1 = conv3x3(inplanes, planes, stride)\n",
    "\t\tself.bn1 = norm_layer(planes)\n",
    "\t\tself.relu = nn.ReLU(inplace=True)\n",
    "\t\tself.conv2 = conv3x3(planes, planes)\n",
    "\t\tself.bn2 = norm_layer(planes)\n",
    "\t\tself.downsample = downsample\n",
    "\t\tself.stride = stride\n",
    "\n",
    "\t\tself.expansion = 2\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tidentity = x\n",
    "\n",
    "\t\tout = self.conv1(x)\n",
    "\t\tout = self.bn1(out)\n",
    "\t\tout = self.relu(out)\n",
    "\n",
    "\t\tout = self.conv2(out)\n",
    "\t\tout = self.bn2(out)\n",
    "\n",
    "\t\tif self.downsample is not None:\n",
    "\t\t\tidentity = self.downsample(x)\n",
    "\n",
    "\t\tout += identity\n",
    "\t\tout = self.relu(out)\n",
    "\n",
    "\t\treturn out\n",
    "\n",
    "\n",
    "class ResNet(Module):\n",
    "\tdef __init__(self, layers, width: int = 2, num_classes=10, zero_init_residual=False,\n",
    "\t\t\t\t groups=1, width_per_group=16, replace_stride_with_dilation=None,\n",
    "\t\t\t\t norm_layer=None):\n",
    "\t\tModule.__init__(self)\n",
    "\n",
    "\t\tif norm_layer is None:\n",
    "\t\t\tnorm_layer = nn.BatchNorm2d\n",
    "\t\tself._norm_layer = norm_layer\n",
    "\n",
    "\t\tblock = BasicBlock\n",
    "\t\tself.inplanes = 16*width\n",
    "\t\tself.dilation = 1\n",
    "\t\tif replace_stride_with_dilation is None:\n",
    "\t\t\t# each element in the tuple indicates if we should replace\n",
    "\t\t\t# the 2x2 stride with a dilated convolution instead\n",
    "\t\t\treplace_stride_with_dilation = [False, False, False]\n",
    "\t\tif len(replace_stride_with_dilation) != 3:\n",
    "\t\t\traise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "\t\t\t\t\t\t\t \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "\t\tself.groups = groups\n",
    "\t\tself.base_width = width_per_group\n",
    "\t\tself.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\t\tself.bn1 = norm_layer(self.inplanes)\n",
    "\t\tself.relu = nn.ReLU(inplace=True)\n",
    "\t\tself.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\t\tself.layer1 = self._make_layer(block, 16*width, layers[0])\n",
    "\t\tself.layer2 = self._make_layer(block, 32*width, layers[1], stride=2,\n",
    "\t\t\t\t\t\t\t\t\t   dilate=replace_stride_with_dilation[0])\n",
    "\t\tself.layer3 = self._make_layer(block, 64*width, layers[2], stride=2,\n",
    "\t\t\t\t\t\t\t\t\t   dilate=replace_stride_with_dilation[1])\n",
    "\n",
    "\t\tself.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\t\tself.fc = nn.Linear(64 * width * block.expansion, num_classes)\n",
    "\n",
    "\t\tfor m in self.modules():\n",
    "\t\t\tif isinstance(m, nn.Conv2d):\n",
    "\t\t\t\tnn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "\t\t\telif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "\t\t\t\tnn.init.constant_(m.weight, 1)\n",
    "\t\t\t\tnn.init.constant_(m.bias, 0)\n",
    "\n",
    "\t\t# Zero-initialize the last BN in each residual branch,\n",
    "\t\t# so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "\t\t# This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "\t\tif zero_init_residual:\n",
    "\t\t\tfor m in self.modules():\n",
    "\t\t\t\tif isinstance(m, BasicBlock):\n",
    "\t\t\t\t\tnn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "\tdef _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "\t\tnorm_layer = self._norm_layer\n",
    "\t\tdownsample = None\n",
    "\t\tprevious_dilation = self.dilation\n",
    "\t\tif dilate:\n",
    "\t\t\tself.dilation *= stride\n",
    "\t\t\tstride = 1\n",
    "\t\tif stride != 1 or self.inplanes != planes * block.expansion:\n",
    "\t\t\tdownsample = nn.Sequential(\n",
    "\t\t\t\tconv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "\t\t\t\tnorm_layer(planes * block.expansion),\n",
    "\t\t\t)\n",
    "\n",
    "\t\tlayers = []\n",
    "\t\tlayers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "\t\t\t\t\t\t\tself.base_width, previous_dilation, norm_layer))\n",
    "\t\tself.inplanes = planes * block.expansion\n",
    "\t\tfor _ in range(1, blocks):\n",
    "\t\t\tlayers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "\t\t\t\t\t\t\t\tbase_width=self.base_width, dilation=self.dilation,\n",
    "\t\t\t\t\t\t\t\tnorm_layer=norm_layer))\n",
    "\n",
    "\t\treturn nn.Sequential(*layers)\n",
    "\n",
    "\tdef _forward_impl(self, x):\n",
    "\t\t# See note [TorchScript super()]\n",
    "\t\tx = self.conv1(x)\n",
    "\t\tx = self.bn1(x)\n",
    "\t\tx = self.relu(x)\n",
    "\t\tx = self.maxpool(x)\n",
    "\n",
    "\t\tx = self.layer1(x)\n",
    "\t\tx = self.layer2(x)\n",
    "\t\tx = self.layer3(x)\n",
    "\n",
    "\t\tx = self.avgpool(x)\n",
    "\t\tx = torch.flatten(x, 1)\n",
    "\t\tx = self.fc(x)\n",
    "\n",
    "\t\treturn x\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\treturn self._forward_impl(x)\n",
    "\n",
    "\n",
    "class WideResNet28(ResNet):\n",
    "\tdef __init__(self, num_classes: int, width: int = 2):\n",
    "\t\tsuper().__init__(layers=[4, 4, 4], width=width, num_classes=num_classes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Learning rate Scheduler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class CosineLRScheduler(LambdaLR):\n",
    "\t\"\"\"\n",
    "\t\tScheduler that decreases the learning rate from lr0 to almost 0 by using the following rule :\n",
    "\t\tlr = lr0 * cos(7 * pi * epoch / (16 * nb_epochs))\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, optim: Optimizer, nb_epochs: int):\n",
    "        # TODO : redo 7\n",
    "\t\tlr_lambda = lambda p_epoch: math.cos(7.0 * math.pi * p_epoch / (16.0 * nb_epochs))\n",
    "\t\tsuper().__init__(optim, lr_lambda)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Build models, optimizer, metrics, and utilities"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Build WideResNet-28-2 model\n",
    "model = WideResNet28(num_classes=10, width=2).to(device)\n",
    "activation = torch.softmax\n",
    "optim = SGD(model.parameters(), lr=lr, weight_decay=weight_decay, momentum=momentum, nesterov=nesterov)\n",
    "scheduler = CosineLRScheduler(optim, nb_epochs=nb_epochs)\n",
    "\n",
    "# Build metrics for labeled, unlabeled and validation predictions.\n",
    "metrics_s = {\"train/acc_s\": CategoricalAccuracy()}\n",
    "metrics_u = {\"train/acc_u\": CategoricalAccuracy()}\n",
    "metrics_val = {\"val/acc\": CategoricalAccuracy()}\n",
    "\n",
    "# Tensorboard writer and the Recorder wrapper for tracking max, std & min of the values stored.\n",
    "writer = SummaryWriter(osp.join(tensorboard_root, \"CIFAR10_%s_WideResNet28_FixMatch\" % get_datetime()))\n",
    "\n",
    "# Class for managing how the values are print in terminal\n",
    "printer = ColumnPrinter()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data preparation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Augmentations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "transform_train_augm_weak = Compose([\n",
    "\tRandomChoice([\n",
    "\t\tRandomHorizontalFlip(0.5),\n",
    "\t\tRandomCrop((32, 32), padding=4),\n",
    "\t]),\n",
    "\tToTensor(),\n",
    "])\n",
    "\n",
    "transform_train_augm_strong = Compose([\n",
    "\tRandAugment(nb_augm_apply=1, magnitude_policy=\"random\"),\n",
    "\tToTensor(),\n",
    "])\n",
    "\n",
    "transform_val = Compose([\n",
    "\tToTensor(),\n",
    "])\n",
    "\n",
    "target_transform = OneHot(nb_classes=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Builds datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset_train_augm_weak = CIFAR10(\n",
    "\tdataset_root, train=True, download=True, transform=transform_train_augm_weak, target_transform=target_transform)\n",
    "dataset_train_augm_strong = CIFAR10(\n",
    "\tdataset_root, train=True, download=True, transform=transform_train_augm_strong, target_transform=target_transform)\n",
    "\n",
    "# Use 4000 data with labels (8%) and 46000 data without labels (92%)\n",
    "supervised_ratio = nb_labels / len(dataset_train_augm_weak)\n",
    "indexes_s, indexes_u = generate_indexes(\n",
    "\tdataset_train_augm_weak,\n",
    "\tnb_classes=10,\n",
    "\tratios=[supervised_ratio, 1.0 - supervised_ratio],\n",
    "\ttarget_one_hot=True,\n",
    ")\n",
    "\n",
    "dataset_train_augm_weak_s = Subset(dataset_train_augm_weak, indexes_s)\n",
    "dataset_train_augm_weak_u = Subset(dataset_train_augm_weak, indexes_u)\n",
    "dataset_train_augm_strong_u = Subset(dataset_train_augm_strong, indexes_u)\n",
    "\n",
    "dataset_train_augm_weak_u = NoLabelDataset(dataset_train_augm_weak_u)\n",
    "dataset_train_augm_strong_u = NoLabelDataset(dataset_train_augm_strong_u)\n",
    "\n",
    "dataset_train_augms_weak_strong_u = ZipDataset([dataset_train_augm_weak_u, dataset_train_augm_strong_u])\n",
    "\n",
    "# Create validation dataset\n",
    "dataset_val = CIFAR10(\n",
    "    dataset_root, train=False, download=True, transform=transform_val, target_transform=target_transform)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ZipCycle class\n",
    "Used for iterate on labeled and unlabeled dataloaders at the same time."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class ZipCycle(Iterable, Sized):\n",
    "\t\"\"\"\n",
    "\t\tZip through a list of iterables and sized objects of different lengths.\n",
    "\t\tReset the iterators when there and finish iteration when the longest one is over.\n",
    "\n",
    "\t\tExample :\n",
    "\t\tr1 = range(1, 4)\n",
    "\t\tr2 = range(1, 6)\n",
    "\t\titers = ZipCycle([r1, r2])\n",
    "\t\tfor v1, v2 in iters:\n",
    "\t\t\tprint(v1, v2)\n",
    "\n",
    "\t\twill print :\n",
    "\t\t1 1\n",
    "\t\t2 2\n",
    "\t\t3 3\n",
    "\t\t1 4\n",
    "\t\t2 5\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(self, iterables: list):\n",
    "\t\tfor iterable in iterables:\n",
    "\t\t\tif len(iterable) == 0:\n",
    "\t\t\t\traise RuntimeError(\"An iterable is empty.\")\n",
    "\n",
    "\t\tself._iterables = iterables\n",
    "\t\tself._len = max([len(iterable) for iterable in self._iterables])\n",
    "\n",
    "\tdef __iter__(self) -> list:\n",
    "\t\tcur_iters = [iter(iterable) for iterable in self._iterables]\n",
    "\t\tcur_count = [0 for _ in self._iterables]\n",
    "\n",
    "\t\tfor _ in range(len(self)):\n",
    "\t\t\titems = []\n",
    "\n",
    "\t\t\tfor i, _ in enumerate(cur_iters):\n",
    "\t\t\t\tif cur_count[i] < len(self._iterables[i]):\n",
    "\t\t\t\t\titem = next(cur_iters[i])\n",
    "\t\t\t\t\tcur_count[i] += 1\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tcur_iters[i] = iter(self._iterables[i])\n",
    "\t\t\t\t\titem = next(cur_iters[i])\n",
    "\t\t\t\t\tcur_count[i] = 1\n",
    "\t\t\t\titems.append(item)\n",
    "\n",
    "\t\t\tyield items\n",
    "\n",
    "\tdef __len__(self) -> int:\n",
    "\t\treturn self._len"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Build loaders"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "bsize_s = bsize\n",
    "bsize_u = bsize * mu\n",
    "\n",
    "loader_train_s_augm = DataLoader(\n",
    "\tdataset=dataset_train_augm_weak_s, batch_size=bsize_s, shuffle=True, num_workers=1, drop_last=False)\n",
    "\n",
    "loader_train_u_augms = DataLoader(\n",
    "\tdataset=dataset_train_augms_weak_strong_u, batch_size=bsize_u, shuffle=True, num_workers=mu, drop_last=False)\n",
    "\n",
    "loader_train = ZipCycle([loader_train_s_augm, loader_train_u_augms])\n",
    "\n",
    "loader_val = DataLoader(dataset=dataset_val, batch_size=bsize, shuffle=False, drop_last=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Criterion"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cross Entropy with probabilities\n",
    "\n",
    "Same as CrossEntropy but accept non-\"onehot encoding\" vectors as targets (labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class CrossEntropyWithVectors(Module):\n",
    "\t\"\"\"\n",
    "\t\tCompute Cross-Entropy between two distributions.\n",
    "\t\tInput and targets must be a batch of probabilities distributions of shape (batch_size, nb_classes) tensor.\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, reduction: str = \"batchmean\", dim: Optional[int] = 1, log_input: bool = False):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.reduce_fn = get_reduction_from_name(reduction)\n",
    "\t\tself.dim = dim\n",
    "\t\tself.log_input = log_input\n",
    "\n",
    "\tdef forward(self, input_: Tensor, targets: Tensor, dim: Optional[int] = None) -> Tensor:\n",
    "\t\t\"\"\"\n",
    "\t\t\tCompute cross-entropy with targets.\n",
    "\t\t\tInput and target must be a (batch_size, nb_classes) tensor.\n",
    "\t\t\"\"\"\n",
    "\t\tif dim is None:\n",
    "\t\t\tdim = self.dim\n",
    "\t\tif not self.log_input:\n",
    "\t\t\tinput_ = torch.log(input_)\n",
    "\t\tloss = -torch.sum(input_ * targets, dim=dim)\n",
    "\t\treturn self.reduce_fn(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### FixMatch loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class FixMatchLoss(Module):\n",
    "\t\"\"\"\n",
    "\t\tFixMatch loss module.\n",
    "\n",
    "\t\tLoss formula : loss = CE(pred_s, label_s) + lambda_u * mask * CE(pred_u, label_u)\n",
    "\n",
    "\t\tThe mask used is 1 if the confidence prediction on weakly augmented data is above a specific threshold.\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(\n",
    "\t\tself,\n",
    "\t\tcriterion_s: Callable = CrossEntropyWithVectors(reduction=\"none\"),\n",
    "\t\tcriterion_u: Callable = CrossEntropyWithVectors(reduction=\"none\"),\n",
    "\t\treduction: str = \"mean\",\n",
    "\t):\n",
    "\t\t\"\"\"\n",
    "\t\t\t:param criterion_s: The criterion used for labeled loss component.\n",
    "\t\t\t:param criterion_u: The criterion used for unlabeled loss component. No reduction must be applied.\n",
    "\t\t\t:param reduction: The main reduction to use. Can be 'none', 'mean', 'batchmean' or 'sum'.\n",
    "\t\t\"\"\"\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.criterion_s = criterion_s\n",
    "\t\tself.criterion_u = criterion_u\n",
    "\t\tself.reduce_fn = get_reduction_from_name(reduction)\n",
    "\n",
    "\tdef forward(\n",
    "\t\tself,\n",
    "\t\tpred_s_augm_weak: Tensor,\n",
    "\t\tpred_u_augm_strong: Tensor,\n",
    "\t\tmask: Tensor,\n",
    "\t\tlabels_s: Tensor,\n",
    "\t\tlabels_u: Tensor,\n",
    "\t\tlambda_s: float = 1.0,\n",
    "\t\tlambda_u: float = 1.0,\n",
    "\t) -> (Tensor, Tensor, Tensor):\n",
    "\t\t\"\"\"\n",
    "\t\t\tCompute FixMatch loss.\n",
    "\n",
    "\t\t\tGeneric :\n",
    "\t\t\t\tloss = lambda_s * mean(criterion_s(pred_s, labels_s)) + lambda_u * mean(criterion_u(pred_u, labels_u) * mask)\n",
    "\n",
    "\t\t\t:param pred_s_augm_weak: Output of the model for labeled batch s of shape (batch_size, nb_classes).\n",
    "\t\t\t:param pred_u_augm_strong: Output of the model for unlabeled batch u of shape (batch_size, nb_classes).\n",
    "\t\t\t:param mask: Binary confidence mask used to avoid using low-confidence labels as targets of shape (batch_size).\n",
    "\t\t\t:param labels_s: True label of labeled batch s of shape (batch_size, nb_classes).\n",
    "\t\t\t:param labels_u: Guessed label of unlabeled batch u of shape (batch_size, nb_classes).\n",
    "\t\t\t:param lambda_s: Coefficient used to multiply the supervised loss component.\n",
    "\t\t\t:param lambda_u: Coefficient used to multiply the unsupervised loss component.\n",
    "\t\t\"\"\"\n",
    "\t\tloss_s = self.criterion_s(pred_s_augm_weak, labels_s)\n",
    "\n",
    "\t\tloss_u = self.criterion_u(pred_u_augm_strong, labels_u)\n",
    "\t\tloss_u *= mask\n",
    "\n",
    "\t\tloss_s = self.reduce_fn(loss_s)\n",
    "\t\tloss_u = self.reduce_fn(loss_u)\n",
    "\n",
    "\t\tloss = lambda_s * loss_s + lambda_u * loss_u\n",
    "\n",
    "\t\treturn loss, loss_s, loss_u"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "criterion = FixMatchLoss(\n",
    "\tcriterion_s=CrossEntropyWithVectors(reduction=\"none\"),\n",
    "\tcriterion_u=CrossEntropyWithVectors(reduction=\"none\")\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def guess_label(batch_u_augm_weak: Tensor) -> (Tensor, Tensor):\n",
    "\tlogits_u_augm_weak = model(batch_u_augm_weak)\n",
    "\tpred_u_augm_weak = activation(logits_u_augm_weak, dim=1)\n",
    "\n",
    "\tnb_classes = pred_u_augm_weak.shape[1]\n",
    "\tlabels_u = one_hot(pred_u_augm_weak.argmax(dim=1), nb_classes)\n",
    "\treturn labels_u, pred_u_augm_weak"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def confidence_mask(pred_weak: Tensor, threshold: float, dim: int) -> Tensor:\n",
    "\tmax_values, _ = pred_weak.max(dim=dim)\n",
    "\treturn (max_values > threshold).float()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def train(epoch: int):\n",
    "\tmodel.train()\n",
    "\n",
    "\tmetric_names = list(metrics_s.keys()) + list(metrics_u.keys()) + \\\n",
    "        [f\"train/{name}\" for name in [\"loss\", \"loss_s\", \"loss_u\", \"labels_used\", \"lr\"]]\n",
    "\tcontinue_metrics = {name: IncrementalMean() for name in metric_names}\n",
    "\n",
    "\tcontinue_metrics[\"train/lr\"].add(get_lr(optim))\n",
    "\n",
    "\tfor i, ((batch_s_augm_weak, labels_s), (batch_u_augm_weak, batch_u_augm_strong)) in enumerate(loader_train):\n",
    "\t\tbatch_s_augm_weak = batch_s_augm_weak.to(device).float()\n",
    "\t\tlabels_s = labels_s.to(device).float()\n",
    "\t\tbatch_u_augm_weak = batch_u_augm_weak.to(device).float()\n",
    "\t\tbatch_u_augm_strong = batch_u_augm_strong.to(device).float()\n",
    "\n",
    "\t\t# Guess label with prediction of weakly augment of u\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tlabels_u, pred_u_augm_weak = guess_label(batch_u_augm_weak)\n",
    "\t\t\tmask = confidence_mask(pred_u_augm_weak, threshold, dim=1)\n",
    "\n",
    "\t\toptim.zero_grad()\n",
    "\n",
    "\t\t# Compute predictions\n",
    "\t\tlogits_s_augm_weak = model(batch_s_augm_weak)\n",
    "\t\tlogits_u_augm_strong = model(batch_u_augm_strong)\n",
    "\n",
    "\t\tpred_s_augm_weak = activation(logits_s_augm_weak, dim=1)\n",
    "\t\tpred_u_augm_strong = activation(logits_u_augm_strong, dim=1)\n",
    "\n",
    "\t\t# Update model\n",
    "\t\tloss, loss_s, loss_u = criterion(\n",
    "\t\t\tpred_s_augm_weak,\n",
    "\t\t\tpred_u_augm_strong,\n",
    "\t\t\tmask,\n",
    "\t\t\tlabels_s,\n",
    "\t\t\tlabels_u,\n",
    "\t\t\tlambda_u=lambda_u\n",
    "\t\t)\n",
    "\n",
    "\t\tloss.backward()\n",
    "\t\toptim.step()\n",
    "\n",
    "\t\t# Compute metrics\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tcontinue_metrics[\"train/loss\"].add(loss.item())\n",
    "\t\t\tcontinue_metrics[\"train/loss_s\"].add(loss_s.item())\n",
    "\t\t\tcontinue_metrics[\"train/loss_u\"].add(loss_u.item())\n",
    "\t\t\tcontinue_metrics[\"train/labels_used\"].add(mask.mean().item())\n",
    "\n",
    "\t\t\tfor name, metric in metrics_s.items():\n",
    "\t\t\t\tscore = metric(pred_s_augm_weak, labels_s)\n",
    "\t\t\t\tcontinue_metrics[name].add(score.item())\n",
    "\n",
    "\t\t\tfor name, metric in metrics_u.items():\n",
    "\t\t\t\tscore = metric(pred_u_augm_strong, labels_u)\n",
    "\t\t\t\tcontinue_metrics[name].add(score.item())\n",
    "\n",
    "\t\t\tcurrent_values = {name: continue_metric.get_current() for name, continue_metric in continue_metrics.items()}\n",
    "\t\t\tprinter.print_current_values(current_values, i, len(loader_train), epoch)\n",
    "\n",
    "\tfor name, continue_metric in continue_metrics.items():\n",
    "\t\twriter.add_scalar(name, continue_metric.get_current(), epoch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def val(epoch: int):\n",
    "\tmodel.eval()\n",
    "\n",
    "\tmetric_names = list(metrics_val.keys())\n",
    "\tcontinue_metrics = {name: IncrementalMean() for name in metric_names}\n",
    "\n",
    "\tfor i, (x, y) in enumerate(loader_val):\n",
    "\t\tx = x.to(device).float()\n",
    "\t\ty = y.to(device).float()\n",
    "\n",
    "\t\t# Compute logits\n",
    "\t\tlogits = model(x)\n",
    "\t\tpred = activation(logits, dim=1)\n",
    "\n",
    "\t\tfor name, metric in metrics_val.items():\n",
    "\t\t\tscore = metric(pred, y)\n",
    "\t\t\tcontinue_metrics[name].add(score.item())\n",
    "\n",
    "\t\tcurrent_values = {name: continue_metric.get_current() for name, continue_metric in continue_metrics.items()}\n",
    "\t\tprinter.print_current_values(current_values, i, len(loader_val), epoch)\n",
    "\n",
    "\tfor name, continue_metric in continue_metrics.items():\n",
    "\t\twriter.add_scalar(name, continue_metric.get_current(), epoch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Start learning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch   1 - 100% - 2.5303e-01 - 8.3703e-01 - 4.7677e-03 - 2.0811e+00 - 2.0809e+00 - 2.1533e-04 - 3.0000e-02 -    6.08    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch   1 - 100% - 2.7687e-01 -    1.62    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch   2 - 100% - 3.6286e-01 - 8.2605e-01 - 4.0719e-03 - 1.7053e+00 - 1.7052e+00 - 1.4632e-04 - 3.0000e-02 -    6.27    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch   2 - 100% - 3.8336e-01 -    1.67    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch   3 - 100% - 4.2764e-01 - 8.1803e-01 - 7.4971e-03 - 1.5394e+00 - 1.5391e+00 - 2.8016e-04 - 2.9998e-02 -    6.26    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch   3 - 100% - 4.1073e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch   4 - 100% - 4.8149e-01 - 8.2256e-01 - 1.2383e-02 - 1.4121e+00 - 1.4115e+00 - 5.6888e-04 - 2.9996e-02 -    6.07    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch   4 - 100% - 4.4904e-01 -    1.57    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch   5 - 100% - 5.2852e-01 - 8.1579e-01 - 3.2589e-02 - 1.3079e+00 - 1.3065e+00 - 1.3859e-03 - 2.9993e-02 -    6.14    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch   5 - 100% - 4.4924e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch   6 - 100% - 5.5567e-01 - 8.1335e-01 - 5.1808e-02 - 1.2211e+00 - 1.2191e+00 - 1.9739e-03 - 2.9990e-02 -    6.17    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch   6 - 100% - 4.2685e-01 -    1.57    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch   7 - 100% - 6.0437e-01 - 8.1538e-01 - 7.5091e-02 - 1.1056e+00 - 1.1026e+00 - 2.9274e-03 - 2.9985e-02 -    6.15    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch   7 - 100% - 5.3075e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch   8 - 100% - 6.3258e-01 - 8.1580e-01 - 1.1262e-01 - 1.0279e+00 - 1.0231e+00 - 4.8043e-03 - 2.9980e-02 -    6.10    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch   8 - 100% - 5.8191e-01 -    1.56    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch   9 - 100% - 6.5291e-01 - 8.1644e-01 - 1.3404e-01 - 9.8349e-01 - 9.7798e-01 - 5.5126e-03 - 2.9974e-02 -    6.09    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch   9 - 100% - 5.6369e-01 -    1.57    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  10 - 100% - 6.7916e-01 - 8.1807e-01 - 1.6412e-01 - 9.1717e-01 - 9.1069e-01 - 6.4873e-03 - 2.9967e-02 -    6.23    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  10 - 100% - 5.2966e-01 -    1.62    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  11 - 100% - 6.9326e-01 - 8.1987e-01 - 1.7982e-01 - 8.8549e-01 - 8.7819e-01 - 7.3007e-03 - 2.9959e-02 -    6.09    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  11 - 100% - 5.6320e-01 -    1.56    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  12 - 100% - 7.0631e-01 - 8.2799e-01 - 2.1253e-01 - 8.2745e-01 - 8.1888e-01 - 8.5716e-03 - 2.9950e-02 -    6.09    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  12 - 100% - 5.8260e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  13 - 100% - 7.2785e-01 - 8.2030e-01 - 2.2116e-01 - 7.8349e-01 - 7.7438e-01 - 9.1070e-03 - 2.9941e-02 -    6.17    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  13 - 100% - 5.7136e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  14 - 100% - 7.5425e-01 - 8.2399e-01 - 2.6182e-01 - 7.0665e-01 - 6.9549e-01 - 1.1159e-02 - 2.9931e-02 -    6.09    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  14 - 100% - 6.0719e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  15 - 100% - 7.6077e-01 - 8.2445e-01 - 2.7742e-01 - 6.9813e-01 - 6.8487e-01 - 1.3261e-02 - 2.9920e-02 -    6.14    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  15 - 100% - 6.1654e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  16 - 100% - 7.8140e-01 - 8.2538e-01 - 3.0171e-01 - 6.4040e-01 - 6.2631e-01 - 1.4092e-02 - 2.9908e-02 -    6.11    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  16 - 100% - 5.8360e-01 -    1.56    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  17 - 100% - 7.9612e-01 - 8.2326e-01 - 3.2272e-01 - 6.1748e-01 - 6.0176e-01 - 1.5716e-02 - 2.9895e-02 -    6.12    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  17 - 100% - 6.5247e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  18 - 100% - 8.0567e-01 - 8.2069e-01 - 3.3459e-01 - 5.9146e-01 - 5.7335e-01 - 1.8110e-02 - 2.9882e-02 -    6.13    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  18 - 100% - 6.3256e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  19 - 100% - 8.1083e-01 - 8.2511e-01 - 3.5607e-01 - 5.5834e-01 - 5.3850e-01 - 1.9838e-02 - 2.9867e-02 -    6.14    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  19 - 100% - 6.2241e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  20 - 100% - 8.3359e-01 - 8.3162e-01 - 3.8413e-01 - 4.9343e-01 - 4.7159e-01 - 2.1838e-02 - 2.9852e-02 -    6.12    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  20 - 100% - 6.4451e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  21 - 100% - 8.2448e-01 - 8.2145e-01 - 3.7731e-01 - 5.1860e-01 - 4.9629e-01 - 2.2304e-02 - 2.9836e-02 -    6.12    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  21 - 100% - 6.4172e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  22 - 100% - 8.3753e-01 - 8.2771e-01 - 4.0379e-01 - 4.9107e-01 - 4.6625e-01 - 2.4820e-02 - 2.9819e-02 -    6.13    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  22 - 100% - 6.2838e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  23 - 100% - 8.4845e-01 - 8.2919e-01 - 4.1184e-01 - 4.5231e-01 - 4.2589e-01 - 2.6426e-02 - 2.9802e-02 -    6.13    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  23 - 100% - 6.3008e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  24 - 100% - 8.5664e-01 - 8.2449e-01 - 4.2984e-01 - 4.3517e-01 - 4.0536e-01 - 2.9812e-02 - 2.9783e-02 -    6.19    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  24 - 100% - 6.2470e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  25 - 100% - 8.7424e-01 - 8.3274e-01 - 4.4915e-01 - 3.8634e-01 - 3.5719e-01 - 2.9150e-02 - 2.9764e-02 -    6.18    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  25 - 100% - 6.4301e-01 -    1.57    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  26 - 100% - 8.8562e-01 - 8.2738e-01 - 4.6332e-01 - 3.6639e-01 - 3.3192e-01 - 3.4472e-02 - 2.9744e-02 -    6.18    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  26 - 100% - 6.5705e-01 -    1.62    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  27 - 100% - 8.8167e-01 - 8.3293e-01 - 4.7388e-01 - 3.7657e-01 - 3.3982e-01 - 3.6747e-02 - 2.9723e-02 -    6.14    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  27 - 100% - 6.3595e-01 -    1.56    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  28 - 100% - 8.9154e-01 - 8.3311e-01 - 4.8086e-01 - 3.5633e-01 - 3.2044e-01 - 3.5888e-02 - 2.9701e-02 -    6.14    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  28 - 100% - 6.8551e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  29 - 100% - 8.9593e-01 - 8.3336e-01 - 4.9478e-01 - 3.3940e-01 - 3.0208e-01 - 3.7320e-02 - 2.9679e-02 -    6.15    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  29 - 100% - 6.4252e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  30 - 100% - 8.8638e-01 - 8.3378e-01 - 4.8451e-01 - 3.6121e-01 - 3.2450e-01 - 3.6717e-02 - 2.9656e-02 -    6.26    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  30 - 100% - 6.7178e-01 -    1.57    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  31 - 100% - 9.0883e-01 - 8.4036e-01 - 5.0567e-01 - 2.9944e-01 - 2.6093e-01 - 3.8511e-02 - 2.9632e-02 -    6.25    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  31 - 100% - 6.5267e-01 -    1.66    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  32 - 100% - 8.9518e-01 - 8.3581e-01 - 5.1188e-01 - 3.2903e-01 - 2.9072e-01 - 3.8305e-02 - 2.9607e-02 -    6.25    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  32 - 100% - 6.7178e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  33 - 100% - 9.0640e-01 - 8.3847e-01 - 5.0966e-01 - 3.0184e-01 - 2.6381e-01 - 3.8035e-02 - 2.9581e-02 -    6.18    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  33 - 100% - 6.3754e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  34 - 100% - 9.0944e-01 - 8.3705e-01 - 5.2019e-01 - 3.1310e-01 - 2.6893e-01 - 4.4163e-02 - 2.9554e-02 -    6.15    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  34 - 100% - 6.4301e-01 -    1.57    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  35 - 100% - 9.1581e-01 - 8.3754e-01 - 5.2100e-01 - 2.8984e-01 - 2.4761e-01 - 4.2228e-02 - 2.9527e-02 -    6.17    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  35 - 100% - 6.5993e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  36 - 100% - 9.2370e-01 - 8.4305e-01 - 5.3663e-01 - 2.6073e-01 - 2.1640e-01 - 4.4334e-02 - 2.9499e-02 -    6.17    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  36 - 100% - 6.7765e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  37 - 100% - 9.2445e-01 - 8.4458e-01 - 5.4721e-01 - 2.6173e-01 - 2.1406e-01 - 4.7677e-02 - 2.9470e-02 -    6.14    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  37 - 100% - 6.2719e-01 -    1.57    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  38 - 100% - 9.2081e-01 - 8.4327e-01 - 5.4134e-01 - 2.6967e-01 - 2.2267e-01 - 4.6996e-02 - 2.9440e-02 -    6.27    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  38 - 100% - 6.6859e-01 -    1.62    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  39 - 100% - 9.2567e-01 - 8.4225e-01 - 5.5115e-01 - 2.5990e-01 - 2.0929e-01 - 5.0609e-02 - 2.9410e-02 -    6.25    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  39 - 100% - 6.6023e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  40 - 100% - 9.2673e-01 - 8.4370e-01 - 5.5272e-01 - 2.5894e-01 - 2.1138e-01 - 4.7563e-02 - 2.9378e-02 -    6.20    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  40 - 100% - 6.7466e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  41 - 100% - 9.3371e-01 - 8.4634e-01 - 5.5197e-01 - 2.3636e-01 - 1.9259e-01 - 4.3770e-02 - 2.9346e-02 -    6.24    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  41 - 100% - 6.7974e-01 -    1.62    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  42 - 100% - 9.4387e-01 - 8.4296e-01 - 5.6671e-01 - 2.1842e-01 - 1.6909e-01 - 4.9327e-02 - 2.9313e-02 -    6.19    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  42 - 100% - 6.5904e-01 -    1.62    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  43 - 100% - 9.3583e-01 - 8.5001e-01 - 5.7725e-01 - 2.3639e-01 - 1.8444e-01 - 5.1953e-02 - 2.9279e-02 -    6.30    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  43 - 100% - 6.6829e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  44 - 100% - 9.4387e-01 - 8.4785e-01 - 5.7227e-01 - 2.2193e-01 - 1.7028e-01 - 5.1646e-02 - 2.9245e-02 -    6.18    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  44 - 100% - 6.6421e-01 -    1.62    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  45 - 100% - 9.4539e-01 - 8.4913e-01 - 5.7021e-01 - 2.0822e-01 - 1.5814e-01 - 5.0079e-02 - 2.9209e-02 -    6.17    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  45 - 100% - 6.7715e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  46 - 100% - 9.3204e-01 - 8.4553e-01 - 5.6267e-01 - 2.4580e-01 - 1.9555e-01 - 5.0250e-02 - 2.9173e-02 -    6.17    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  46 - 100% - 6.5336e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  47 - 100% - 9.5221e-01 - 8.4916e-01 - 5.8643e-01 - 1.9523e-01 - 1.4159e-01 - 5.3641e-02 - 2.9136e-02 -    6.25    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  47 - 100% - 6.8899e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  48 - 100% - 9.4827e-01 - 8.4971e-01 - 5.8298e-01 - 2.1209e-01 - 1.6143e-01 - 5.0663e-02 - 2.9098e-02 -    6.23    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  48 - 100% - 6.8402e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  49 - 100% - 9.3871e-01 - 8.5231e-01 - 5.8015e-01 - 2.2329e-01 - 1.7599e-01 - 4.7298e-02 - 2.9060e-02 -    6.15    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  49 - 100% - 6.7685e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  50 - 100% - 9.4600e-01 - 8.5075e-01 - 5.8244e-01 - 2.0780e-01 - 1.5436e-01 - 5.3442e-02 - 2.9020e-02 -    6.18    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  50 - 100% - 6.9258e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  51 - 100% - 9.5646e-01 - 8.5232e-01 - 5.9263e-01 - 1.8534e-01 - 1.3448e-01 - 5.0856e-02 - 2.8980e-02 -    6.15    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  51 - 100% - 6.9178e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  52 - 100% - 9.5752e-01 - 8.5159e-01 - 6.0003e-01 - 1.8816e-01 - 1.3622e-01 - 5.1943e-02 - 2.8939e-02 -    6.16    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  52 - 100% - 6.5894e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  53 - 100% - 9.4266e-01 - 8.5096e-01 - 5.9629e-01 - 2.1440e-01 - 1.6058e-01 - 5.3823e-02 - 2.8898e-02 -    6.18    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  53 - 100% - 6.4829e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  54 - 100% - 9.5373e-01 - 8.5525e-01 - 5.9167e-01 - 1.8707e-01 - 1.3992e-01 - 4.7159e-02 - 2.8855e-02 -    6.15    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  54 - 100% - 6.9646e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  55 - 100% - 9.5282e-01 - 8.5149e-01 - 6.0037e-01 - 1.9420e-01 - 1.3710e-01 - 5.7105e-02 - 2.8812e-02 -    6.20    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  55 - 100% - 6.7725e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  56 - 100% - 9.5146e-01 - 8.5362e-01 - 6.0002e-01 - 1.9746e-01 - 1.4321e-01 - 5.4249e-02 - 2.8768e-02 -    6.25    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  56 - 100% - 6.8242e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  57 - 100% - 9.5510e-01 - 8.5720e-01 - 6.0222e-01 - 1.8368e-01 - 1.3300e-01 - 5.0680e-02 - 2.8723e-02 -    6.17    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  57 - 100% - 6.9427e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  58 - 100% - 9.4994e-01 - 8.5365e-01 - 5.9500e-01 - 1.9531e-01 - 1.4565e-01 - 4.9666e-02 - 2.8677e-02 -    6.26    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  58 - 100% - 6.6551e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  59 - 100% - 9.5267e-01 - 8.5642e-01 - 5.9648e-01 - 1.8615e-01 - 1.3691e-01 - 4.9243e-02 - 2.8631e-02 -    6.19    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  59 - 100% - 6.9586e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  60 - 100% - 9.5904e-01 - 8.5717e-01 - 6.0554e-01 - 1.6675e-01 - 1.1558e-01 - 5.1169e-02 - 2.8583e-02 -    6.20    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  60 - 100% - 6.6451e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  61 - 100% - 9.5980e-01 - 8.5706e-01 - 6.1051e-01 - 1.7250e-01 - 1.1832e-01 - 5.4176e-02 - 2.8535e-02 -    6.20    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  61 - 100% - 7.0203e-01 -    1.62    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  62 - 100% - 9.6450e-01 - 8.5832e-01 - 6.2321e-01 - 1.5965e-01 - 1.0442e-01 - 5.5227e-02 - 2.8487e-02 -    6.22    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  62 - 100% - 6.9576e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  63 - 100% - 9.5737e-01 - 8.5696e-01 - 6.1651e-01 - 1.7393e-01 - 1.1976e-01 - 5.4165e-02 - 2.8437e-02 -    6.18    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  63 - 100% - 7.0074e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  64 - 100% - 9.6359e-01 - 8.5780e-01 - 6.2058e-01 - 1.5913e-01 - 1.0490e-01 - 5.4231e-02 - 2.8387e-02 -    6.16    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  64 - 100% - 6.5973e-01 -    1.62    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  65 - 100% - 9.5085e-01 - 8.5390e-01 - 5.9977e-01 - 2.0195e-01 - 1.4962e-01 - 5.2331e-02 - 2.8335e-02 -    6.18    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  65 - 100% - 6.8262e-01 -    1.57    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  66 - 100% - 9.5707e-01 - 8.5783e-01 - 6.1281e-01 - 1.7829e-01 - 1.2430e-01 - 5.3990e-02 - 2.8284e-02 -    6.24    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  66 - 100% - 6.8372e-01 -    1.57    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  67 - 100% - 9.5206e-01 - 8.5493e-01 - 6.0999e-01 - 1.9550e-01 - 1.4033e-01 - 5.5169e-02 - 2.8231e-02 -    6.15    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  67 - 100% - 6.7934e-01 -    1.65    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  68 - 100% - 9.5768e-01 - 8.5487e-01 - 6.0865e-01 - 1.9115e-01 - 1.3443e-01 - 5.6719e-02 - 2.8177e-02 -    6.16    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  68 - 100% - 6.7814e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  69 - 100% - 9.5904e-01 - 8.6108e-01 - 6.1971e-01 - 1.7264e-01 - 1.1924e-01 - 5.3405e-02 - 2.8123e-02 -    6.18    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  69 - 100% - 6.8282e-01 -    1.57    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  70 - 100% - 9.5039e-01 - 8.5334e-01 - 5.9199e-01 - 1.9675e-01 - 1.4652e-01 - 5.0231e-02 - 2.8068e-02 -    6.15    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  70 - 100% - 6.8451e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  71 - 100% - 9.5828e-01 - 8.5698e-01 - 6.0016e-01 - 1.7311e-01 - 1.2254e-01 - 5.0563e-02 - 2.8012e-02 -    6.17    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  71 - 100% - 6.8153e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  72 - 100% - 9.6253e-01 - 8.5982e-01 - 6.1089e-01 - 1.6235e-01 - 1.1319e-01 - 4.9154e-02 - 2.7956e-02 -    6.16    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  72 - 100% - 6.7685e-01 -    1.56    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  73 - 100% - 9.6602e-01 - 8.5774e-01 - 6.1594e-01 - 1.5964e-01 - 1.0571e-01 - 5.3928e-02 - 2.7898e-02 -    6.14    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  73 - 100% - 6.8402e-01 -    1.57    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  74 - 100% - 9.6025e-01 - 8.5515e-01 - 6.0950e-01 - 1.7342e-01 - 1.1969e-01 - 5.3736e-02 - 2.7840e-02 -    6.17    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  74 - 100% - 6.9974e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  75 - 100% - 9.6238e-01 - 8.6303e-01 - 6.2377e-01 - 1.6261e-01 - 1.1105e-01 - 5.1567e-02 - 2.7782e-02 -    6.17    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  75 - 100% - 6.8730e-01 -    1.57    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  76 - 100% - 9.6632e-01 - 8.6283e-01 - 6.2044e-01 - 1.4880e-01 - 1.0154e-01 - 4.7257e-02 - 2.7722e-02 -    6.15    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  76 - 100% - 6.8621e-01 -    1.57    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  77 - 100% - 9.6496e-01 - 8.6220e-01 - 6.2811e-01 - 1.5962e-01 - 1.0571e-01 - 5.3911e-02 - 2.7662e-02 -    6.21    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  77 - 100% - 6.9188e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  78 - 100% - 9.5889e-01 - 8.5792e-01 - 6.1398e-01 - 1.7652e-01 - 1.2392e-01 - 5.2602e-02 - 2.7601e-02 -    6.21    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  78 - 100% - 6.9885e-01 -    1.57    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  79 - 100% - 9.5646e-01 - 8.5881e-01 - 6.1513e-01 - 1.7282e-01 - 1.2117e-01 - 5.1654e-02 - 2.7539e-02 -    6.16    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  79 - 100% - 6.9855e-01 -    1.62    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  80 - 100% - 9.6177e-01 - 8.5948e-01 - 6.1457e-01 - 1.6661e-01 - 1.1356e-01 - 5.3045e-02 - 2.7476e-02 -    6.17    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  80 - 100% - 7.1377e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  81 - 100% - 9.6996e-01 - 8.6537e-01 - 6.2958e-01 - 1.4826e-01 - 9.4153e-02 - 5.4112e-02 - 2.7413e-02 -    6.21    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  81 - 100% - 7.0054e-01 -    1.57    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  82 - 100% - 9.6647e-01 - 8.6003e-01 - 6.2552e-01 - 1.6570e-01 - 1.1035e-01 - 5.5356e-02 - 2.7349e-02 -    6.16    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  82 - 100% - 6.9686e-01 -    1.57    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  83 - 100% - 9.6632e-01 - 8.6065e-01 - 6.2876e-01 - 1.5314e-01 - 9.7743e-02 - 5.5399e-02 - 2.7284e-02 -    6.16    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  83 - 100% - 6.9397e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  84 - 100% - 9.6253e-01 - 8.6239e-01 - 6.3005e-01 - 1.6928e-01 - 1.1379e-01 - 5.5492e-02 - 2.7218e-02 -    6.16    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  84 - 100% - 6.9676e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  85 - 100% - 9.6450e-01 - 8.6069e-01 - 6.2666e-01 - 1.5403e-01 - 1.0107e-01 - 5.2956e-02 - 2.7152e-02 -    6.17    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  85 - 100% - 7.0900e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  86 - 100% - 9.7072e-01 - 8.6406e-01 - 6.3122e-01 - 1.4313e-01 - 8.9946e-02 - 5.3188e-02 - 2.7085e-02 -    6.27    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  86 - 100% - 6.9666e-01 -    1.62    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  87 - 100% - 9.6268e-01 - 8.6518e-01 - 6.3105e-01 - 1.5963e-01 - 1.0628e-01 - 5.3352e-02 - 2.7017e-02 -    6.19    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  87 - 100% - 6.7924e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  88 - 100% - 9.6086e-01 - 8.6081e-01 - 6.1982e-01 - 1.7200e-01 - 1.1593e-01 - 5.6070e-02 - 2.6948e-02 -    6.19    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  88 - 100% - 6.9686e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  89 - 100% - 9.6465e-01 - 8.6633e-01 - 6.2772e-01 - 1.6085e-01 - 1.1009e-01 - 5.0762e-02 - 2.6879e-02 -    6.16    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  89 - 100% - 7.0681e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  90 - 100% - 9.6784e-01 - 8.6501e-01 - 6.2867e-01 - 1.5657e-01 - 1.0296e-01 - 5.3606e-02 - 2.6809e-02 -    6.27    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  90 - 100% - 7.0054e-01 -    1.62    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  91 - 100% - 9.6374e-01 - 8.6001e-01 - 6.2346e-01 - 1.6106e-01 - 1.0768e-01 - 5.3377e-02 - 2.6738e-02 -    6.17    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  91 - 100% - 6.9904e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  92 - 100% - 9.6708e-01 - 8.6543e-01 - 6.3037e-01 - 1.4908e-01 - 9.9433e-02 - 4.9651e-02 - 2.6667e-02 -    6.16    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  92 - 100% - 6.9068e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  93 - 100% - 9.7254e-01 - 8.6699e-01 - 6.4034e-01 - 1.3437e-01 - 8.1104e-02 - 5.3266e-02 - 2.6594e-02 -    6.19    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  93 - 100% - 7.0840e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  94 - 100% - 9.6299e-01 - 8.6219e-01 - 6.3413e-01 - 1.6086e-01 - 1.0595e-01 - 5.4912e-02 - 2.6522e-02 -    6.15    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  94 - 100% - 7.0113e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  95 - 100% - 9.6526e-01 - 8.6720e-01 - 6.3300e-01 - 1.5377e-01 - 9.8772e-02 - 5.5003e-02 - 2.6448e-02 -    6.22    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  95 - 100% - 7.0392e-01 -    1.57    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  96 - 100% - 9.7178e-01 - 8.6910e-01 - 6.3464e-01 - 1.4181e-01 - 9.1084e-02 - 5.0723e-02 - 2.6373e-02 -    6.17    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  96 - 100% - 6.9785e-01 -    1.62    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  97 - 100% - 9.7027e-01 - 8.6953e-01 - 6.3638e-01 - 1.3825e-01 - 8.8189e-02 - 5.0064e-02 - 2.6298e-02 -    6.17    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  97 - 100% - 6.9357e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  98 - 100% - 9.6496e-01 - 8.6424e-01 - 6.2613e-01 - 1.5828e-01 - 1.0587e-01 - 5.2401e-02 - 2.6222e-02 -    6.15    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  98 - 100% - 7.0780e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch  99 - 100% - 9.6708e-01 - 8.6663e-01 - 6.3252e-01 - 1.4704e-01 - 9.4971e-02 - 5.2071e-02 - 2.6146e-02 -    6.30    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch  99 - 100% - 6.9019e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 100 - 100% - 9.6268e-01 - 8.6373e-01 - 6.2518e-01 - 1.5879e-01 - 1.0918e-01 - 4.9608e-02 - 2.6069e-02 -    6.25    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 100 - 100% - 7.1517e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 101 - 100% - 9.7816e-01 - 8.7101e-01 - 6.4527e-01 - 1.1694e-01 - 6.8027e-02 - 4.8910e-02 - 2.5991e-02 -    6.17    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 101 - 100% - 7.1437e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 102 - 100% - 9.6981e-01 - 8.6564e-01 - 6.4468e-01 - 1.4517e-01 - 8.8080e-02 - 5.7094e-02 - 2.5912e-02 -    6.18    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 102 - 100% - 7.0541e-01 -    1.62    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 103 - 100% - 9.6663e-01 - 8.6653e-01 - 6.3977e-01 - 1.4851e-01 - 9.3226e-02 - 5.5282e-02 - 2.5832e-02 -    6.16    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 103 - 100% - 7.0651e-01 -    1.62    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 104 - 100% - 9.6981e-01 - 8.7345e-01 - 6.4666e-01 - 1.4416e-01 - 9.1046e-02 - 5.3113e-02 - 2.5752e-02 -    6.16    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 104 - 100% - 7.1168e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 105 - 100% - 9.7072e-01 - 8.7492e-01 - 6.5369e-01 - 1.3992e-01 - 8.6925e-02 - 5.2993e-02 - 2.5672e-02 -    6.19    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 105 - 100% - 7.0969e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 106 - 100% - 9.6496e-01 - 8.6789e-01 - 6.3601e-01 - 1.5526e-01 - 1.0181e-01 - 5.3443e-02 - 2.5590e-02 -    6.21    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 106 - 100% - 7.1915e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 107 - 100% - 9.6738e-01 - 8.6893e-01 - 6.3887e-01 - 1.4576e-01 - 9.4568e-02 - 5.1188e-02 - 2.5508e-02 -    6.15    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 107 - 100% - 7.0920e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 108 - 100% - 9.7148e-01 - 8.6507e-01 - 6.4226e-01 - 1.4674e-01 - 8.9342e-02 - 5.7401e-02 - 2.5425e-02 -    6.16    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 108 - 100% - 7.1268e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 109 - 100% - 9.7042e-01 - 8.6525e-01 - 6.3264e-01 - 1.4730e-01 - 8.9113e-02 - 5.8190e-02 - 2.5341e-02 -    6.16    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 109 - 100% - 7.0959e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 110 - 100% - 9.7527e-01 - 8.6920e-01 - 6.4309e-01 - 1.2335e-01 - 6.9771e-02 - 5.3578e-02 - 2.5257e-02 -    6.13    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 110 - 100% - 6.9297e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 111 - 100% - 9.6647e-01 - 8.7141e-01 - 6.4904e-01 - 1.5057e-01 - 9.7042e-02 - 5.3528e-02 - 2.5172e-02 -    6.21    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 111 - 100% - 7.0740e-01 -    1.57    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 112 - 100% - 9.7467e-01 - 8.7581e-01 - 6.5638e-01 - 1.3011e-01 - 7.7887e-02 - 5.2223e-02 - 2.5086e-02 -    6.20    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 112 - 100% - 7.1984e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 113 - 100% - 9.6875e-01 - 8.6964e-01 - 6.5029e-01 - 1.4897e-01 - 9.5969e-02 - 5.3006e-02 - 2.5000e-02 -    6.19    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 113 - 100% - 7.0551e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 114 - 100% - 9.7709e-01 - 8.6626e-01 - 6.4249e-01 - 1.2966e-01 - 7.4691e-02 - 5.4967e-02 - 2.4913e-02 -    6.18    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 114 - 100% - 7.1586e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 115 - 100% - 9.7133e-01 - 8.7166e-01 - 6.5117e-01 - 1.3234e-01 - 8.0112e-02 - 5.2223e-02 - 2.4825e-02 -    6.19    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 115 - 100% - 7.1507e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 116 - 100% - 9.7709e-01 - 8.6978e-01 - 6.5645e-01 - 1.2316e-01 - 7.0589e-02 - 5.2567e-02 - 2.4737e-02 -    6.28    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 116 - 100% - 7.1208e-01 -    1.64    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 117 - 100% - 9.6738e-01 - 8.7179e-01 - 6.4770e-01 - 1.5207e-01 - 1.0031e-01 - 5.1754e-02 - 2.4647e-02 -    6.20    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 117 - 100% - 6.8999e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 118 - 100% - 9.6117e-01 - 8.6661e-01 - 6.3188e-01 - 1.5779e-01 - 1.0486e-01 - 5.2924e-02 - 2.4558e-02 -    6.21    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 118 - 100% - 7.0442e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 119 - 100% - 9.5980e-01 - 8.6753e-01 - 6.3122e-01 - 1.7685e-01 - 1.2144e-01 - 5.5408e-02 - 2.4467e-02 -    6.25    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 119 - 100% - 6.9815e-01 -    1.62    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 120 - 100% - 9.7360e-01 - 8.7595e-01 - 6.3754e-01 - 1.2913e-01 - 8.2158e-02 - 4.6972e-02 - 2.4376e-02 -    6.17    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 120 - 100% - 7.1855e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 121 - 100% - 9.7891e-01 - 8.7331e-01 - 6.4679e-01 - 1.1701e-01 - 6.5567e-02 - 5.1445e-02 - 2.4284e-02 -    6.22    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 121 - 100% - 7.0412e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 122 - 100% - 9.7406e-01 - 8.6926e-01 - 6.4891e-01 - 1.2956e-01 - 7.6886e-02 - 5.2672e-02 - 2.4192e-02 -    6.19    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 122 - 100% - 7.0293e-01 -    1.62    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 123 - 100% - 9.6951e-01 - 8.6871e-01 - 6.5264e-01 - 1.3946e-01 - 8.3161e-02 - 5.6301e-02 - 2.4099e-02 -    6.22    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 123 - 100% - 6.9536e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 124 - 100% - 9.7679e-01 - 8.7281e-01 - 6.5662e-01 - 1.2226e-01 - 6.8814e-02 - 5.3443e-02 - 2.4005e-02 -    6.20    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 124 - 100% - 7.1716e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 125 - 100% - 9.8013e-01 - 8.7038e-01 - 6.5559e-01 - 1.2359e-01 - 6.6153e-02 - 5.7432e-02 - 2.3911e-02 -    6.27    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 125 - 100% - 7.1298e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 126 - 100% - 9.8089e-01 - 8.7523e-01 - 6.6231e-01 - 1.1239e-01 - 5.9877e-02 - 5.2517e-02 - 2.3816e-02 -    6.33    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 126 - 100% - 7.0890e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 127 - 100% - 9.8043e-01 - 8.7646e-01 - 6.6870e-01 - 1.1320e-01 - 5.9321e-02 - 5.3876e-02 - 2.3720e-02 -    6.18    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 127 - 100% - 7.1636e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 128 - 100% - 9.7087e-01 - 8.7588e-01 - 6.6843e-01 - 1.3670e-01 - 8.0644e-02 - 5.6057e-02 - 2.3623e-02 -    6.19    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 128 - 100% - 6.8203e-01 -    1.62    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 129 - 100% - 9.7482e-01 - 8.7042e-01 - 6.5727e-01 - 1.2803e-01 - 7.2666e-02 - 5.5366e-02 - 2.3526e-02 -    6.17    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 129 - 100% - 6.9914e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 130 - 100% - 9.7163e-01 - 8.7243e-01 - 6.5575e-01 - 1.4064e-01 - 8.6615e-02 - 5.4030e-02 - 2.3429e-02 -    6.23    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 130 - 100% - 7.0820e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 131 - 100% - 9.7800e-01 - 8.7007e-01 - 6.4801e-01 - 1.2090e-01 - 6.8392e-02 - 5.2512e-02 - 2.3330e-02 -    6.17    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 131 - 100% - 7.1119e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 132 - 100% - 9.7709e-01 - 8.7066e-01 - 6.5190e-01 - 1.2571e-01 - 7.0964e-02 - 5.4747e-02 - 2.3231e-02 -    6.23    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 132 - 100% - 7.1756e-01 -    1.57    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 133 - 100% - 9.7300e-01 - 8.6915e-01 - 6.5264e-01 - 1.4030e-01 - 8.4247e-02 - 5.6054e-02 - 2.3132e-02 -    6.18    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 133 - 100% - 6.9556e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 134 - 100% - 9.7588e-01 - 8.7267e-01 - 6.5377e-01 - 1.3069e-01 - 7.4268e-02 - 5.6417e-02 - 2.3032e-02 -    6.22    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 134 - 100% - 7.0084e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 135 - 100% - 9.7603e-01 - 8.7082e-01 - 6.5891e-01 - 1.2943e-01 - 7.2260e-02 - 5.7169e-02 - 2.2931e-02 -    6.20    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 135 - 100% - 7.0770e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 136 - 100% - 9.7345e-01 - 8.7203e-01 - 6.5260e-01 - 1.3298e-01 - 7.9382e-02 - 5.3601e-02 - 2.2829e-02 -    6.30    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 136 - 100% - 7.1905e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 137 - 100% - 9.8013e-01 - 8.7754e-01 - 6.6359e-01 - 1.0661e-01 - 5.6228e-02 - 5.0385e-02 - 2.2727e-02 -    6.17    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 137 - 100% - 7.0372e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 138 - 100% - 9.7588e-01 - 8.7299e-01 - 6.6148e-01 - 1.2545e-01 - 7.0523e-02 - 5.4931e-02 - 2.2625e-02 -    6.25    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 138 - 100% - 7.1407e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 139 - 100% - 9.7254e-01 - 8.7015e-01 - 6.5862e-01 - 1.3525e-01 - 7.9686e-02 - 5.5568e-02 - 2.2521e-02 -    6.22    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 139 - 100% - 7.0521e-01 -    1.62    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 140 - 100% - 9.7785e-01 - 8.7563e-01 - 6.5455e-01 - 1.2108e-01 - 7.4243e-02 - 4.6839e-02 - 2.2417e-02 -    6.25    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 140 - 100% - 7.2621e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 141 - 100% - 9.7679e-01 - 8.7437e-01 - 6.6742e-01 - 1.2331e-01 - 7.0956e-02 - 5.2358e-02 - 2.2313e-02 -    6.20    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 141 - 100% - 6.9168e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 142 - 100% - 9.7300e-01 - 8.7071e-01 - 6.5501e-01 - 1.3226e-01 - 8.0984e-02 - 5.1273e-02 - 2.2208e-02 -    6.23    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 142 - 100% - 7.2343e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 143 - 100% - 9.8043e-01 - 8.7570e-01 - 6.6937e-01 - 1.1245e-01 - 5.9365e-02 - 5.3087e-02 - 2.2102e-02 -    6.18    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 143 - 100% - 6.8740e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 144 - 100% - 9.8013e-01 - 8.7838e-01 - 6.7292e-01 - 1.0576e-01 - 5.6332e-02 - 4.9432e-02 - 2.1995e-02 -    6.23    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 144 - 100% - 7.2034e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 145 - 100% - 9.7816e-01 - 8.7551e-01 - 6.6499e-01 - 1.2276e-01 - 6.6676e-02 - 5.6086e-02 - 2.1888e-02 -    6.21    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 145 - 100% - 7.1178e-01 -    1.64    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 146 - 100% - 9.7998e-01 - 8.7655e-01 - 6.6853e-01 - 1.1070e-01 - 6.0309e-02 - 5.0386e-02 - 2.1781e-02 -    6.19    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 146 - 100% - 7.2223e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 147 - 100% - 9.8271e-01 - 8.8208e-01 - 6.7866e-01 - 1.0701e-01 - 5.5712e-02 - 5.1302e-02 - 2.1673e-02 -    6.18    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 147 - 100% - 7.1079e-01 -    1.63    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 148 - 100% - 9.7694e-01 - 8.7748e-01 - 6.6831e-01 - 1.2585e-01 - 7.2336e-02 - 5.3513e-02 - 2.1564e-02 -    6.21    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 148 - 100% - 7.0541e-01 -    1.63    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 149 - 100% - 9.7633e-01 - 8.7240e-01 - 6.6496e-01 - 1.2588e-01 - 6.9972e-02 - 5.5904e-02 - 2.1455e-02 -    6.19    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 149 - 100% - 7.0880e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 150 - 100% - 9.7664e-01 - 8.7351e-01 - 6.5969e-01 - 1.2664e-01 - 7.1549e-02 - 5.5093e-02 - 2.1345e-02 -    6.22    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 150 - 100% - 7.0880e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 151 - 100% - 9.7967e-01 - 8.7804e-01 - 6.7239e-01 - 1.1174e-01 - 6.1553e-02 - 5.0191e-02 - 2.1234e-02 -    6.29    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 151 - 100% - 6.9098e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 152 - 100% - 9.8286e-01 - 8.7748e-01 - 6.6855e-01 - 1.0959e-01 - 5.7038e-02 - 5.2550e-02 - 2.1123e-02 -    6.20    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 152 - 100% - 7.0800e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 153 - 100% - 9.8225e-01 - 8.7893e-01 - 6.7542e-01 - 1.0621e-01 - 5.6328e-02 - 4.9883e-02 - 2.1011e-02 -    6.32    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 153 - 100% - 7.2731e-01 -    1.63    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 154 - 100% - 9.8286e-01 - 8.7719e-01 - 6.7022e-01 - 1.0420e-01 - 5.3873e-02 - 5.0327e-02 - 2.0899e-02 -    6.31    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 154 - 100% - 7.0920e-01 -    1.57    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 155 - 100% - 9.8877e-01 - 8.8212e-01 - 6.8806e-01 - 8.5878e-02 - 3.5518e-02 - 5.0360e-02 - 2.0786e-02 -    6.13    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 155 - 100% - 7.3229e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 156 - 100% - 9.7482e-01 - 8.7626e-01 - 6.7042e-01 - 1.3037e-01 - 7.5060e-02 - 5.5306e-02 - 2.0673e-02 -    6.14    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 156 - 100% - 6.8750e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 157 - 100% - 9.7269e-01 - 8.7420e-01 - 6.4908e-01 - 1.3340e-01 - 8.3638e-02 - 4.9764e-02 - 2.0559e-02 -    6.11    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 157 - 100% - 7.2283e-01 -    1.57    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 158 - 100% - 9.7952e-01 - 8.7722e-01 - 6.6655e-01 - 1.1051e-01 - 6.2805e-02 - 4.7708e-02 - 2.0444e-02 -    6.13    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 158 - 100% - 7.1069e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 159 - 100% - 9.8028e-01 - 8.7348e-01 - 6.6109e-01 - 1.1665e-01 - 6.5169e-02 - 5.1485e-02 - 2.0329e-02 -    6.15    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 159 - 100% - 7.1984e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 160 - 100% - 9.8635e-01 - 8.8458e-01 - 6.8203e-01 - 9.2173e-02 - 4.2987e-02 - 4.9186e-02 - 2.0213e-02 -    6.18    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 160 - 100% - 7.2602e-01 -    1.55    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 161 - 100% - 9.8635e-01 - 8.8099e-01 - 6.8491e-01 - 9.3302e-02 - 4.2966e-02 - 5.0336e-02 - 2.0097e-02 -    6.26    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 161 - 100% - 7.2472e-01 -    1.57    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 162 - 100% - 9.7770e-01 - 8.8259e-01 - 6.8359e-01 - 1.2054e-01 - 6.7001e-02 - 5.3541e-02 - 1.9981e-02 -    6.12    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 162 - 100% - 7.2353e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 163 - 100% - 9.8544e-01 - 8.7909e-01 - 6.7239e-01 - 9.1797e-02 - 4.3792e-02 - 4.8005e-02 - 1.9863e-02 -    6.14    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 163 - 100% - 7.2661e-01 -    1.57    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 164 - 100% - 9.8225e-01 - 8.8152e-01 - 6.7731e-01 - 1.0735e-01 - 5.7492e-02 - 4.9859e-02 - 1.9745e-02 -    6.15    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 164 - 100% - 7.2621e-01 -    1.56    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 165 - 100% - 9.8422e-01 - 8.8165e-01 - 6.7758e-01 - 1.0132e-01 - 4.9019e-02 - 5.2302e-02 - 1.9627e-02 -    6.14    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 165 - 100% - 7.2850e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 166 - 100% - 9.8786e-01 - 8.8278e-01 - 6.8458e-01 - 9.0387e-02 - 3.7270e-02 - 5.3117e-02 - 1.9508e-02 -    6.14    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 166 - 100% - 7.2174e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 167 - 100% - 9.7907e-01 - 8.8151e-01 - 6.8092e-01 - 1.1534e-01 - 6.2578e-02 - 5.2758e-02 - 1.9389e-02 -    6.17    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 167 - 100% - 7.1905e-01 -    1.56    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 168 - 100% - 9.8104e-01 - 8.7875e-01 - 6.7888e-01 - 1.0555e-01 - 5.5864e-02 - 4.9683e-02 - 1.9269e-02 -    6.14    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 168 - 100% - 7.1457e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 169 - 100% - 9.8604e-01 - 8.8551e-01 - 6.9063e-01 - 9.2466e-02 - 4.0107e-02 - 5.2359e-02 - 1.9148e-02 -    6.27    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 169 - 100% - 7.2820e-01 -    1.55    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 170 - 100% - 9.8331e-01 - 8.8540e-01 - 6.9368e-01 - 1.0583e-01 - 5.2485e-02 - 5.3346e-02 - 1.9027e-02 -    6.12    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 170 - 100% - 7.2482e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 171 - 100% - 9.7982e-01 - 8.8120e-01 - 6.7660e-01 - 1.1312e-01 - 6.1213e-02 - 5.1906e-02 - 1.8906e-02 -    6.24    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 171 - 100% - 7.0840e-01 -    1.57    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 172 - 100% - 9.8377e-01 - 8.8369e-01 - 6.7723e-01 - 9.8950e-02 - 5.1974e-02 - 4.6976e-02 - 1.8783e-02 -    6.26    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 172 - 100% - 7.2144e-01 -    1.57    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 173 - 100% - 9.8286e-01 - 8.8409e-01 - 6.8037e-01 - 9.7508e-02 - 4.9367e-02 - 4.8141e-02 - 1.8661e-02 -    6.23    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 173 - 100% - 7.2552e-01 -    1.57    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 174 - 100% - 9.8301e-01 - 8.8416e-01 - 6.8516e-01 - 1.0198e-01 - 5.0601e-02 - 5.1376e-02 - 1.8538e-02 -    6.17    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 174 - 100% - 7.2661e-01 -    1.57    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 175 - 100% - 9.9014e-01 - 8.8919e-01 - 6.9272e-01 - 8.3520e-02 - 3.4778e-02 - 4.8743e-02 - 1.8414e-02 -    6.12    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 175 - 100% - 7.3209e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 176 - 100% - 9.8999e-01 - 8.8693e-01 - 7.0309e-01 - 8.4479e-02 - 3.2639e-02 - 5.1840e-02 - 1.8290e-02 -    6.15    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 176 - 100% - 7.1805e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 177 - 100% - 9.8271e-01 - 8.8586e-01 - 6.9461e-01 - 9.8168e-02 - 4.7552e-02 - 5.0616e-02 - 1.8165e-02 -    6.13    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 177 - 100% - 7.0541e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 178 - 100% - 9.8923e-01 - 8.8630e-01 - 6.8803e-01 - 9.1145e-02 - 4.1451e-02 - 4.9694e-02 - 1.8040e-02 -    6.16    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 178 - 100% - 7.3577e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 179 - 100% - 9.8908e-01 - 8.8937e-01 - 7.0425e-01 - 8.2191e-02 - 3.3907e-02 - 4.8283e-02 - 1.7915e-02 -    6.18    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 179 - 100% - 7.1457e-01 -    1.57    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 180 - 100% - 9.7937e-01 - 8.8148e-01 - 6.8471e-01 - 1.1294e-01 - 6.0455e-02 - 5.2487e-02 - 1.7789e-02 -    6.16    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 180 - 100% - 7.3129e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 181 - 100% - 9.8073e-01 - 8.8234e-01 - 6.8190e-01 - 1.1004e-01 - 5.7992e-02 - 5.2048e-02 - 1.7662e-02 -    6.12    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 181 - 100% - 7.3139e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 182 - 100% - 9.8877e-01 - 8.8874e-01 - 7.0221e-01 - 8.4308e-02 - 3.6562e-02 - 4.7746e-02 - 1.7535e-02 -    6.14    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 182 - 100% - 7.2462e-01 -    1.57    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 183 - 100% - 9.8604e-01 - 8.8764e-01 - 6.9480e-01 - 9.3836e-02 - 4.3431e-02 - 5.0405e-02 - 1.7408e-02 -    6.27    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 183 - 100% - 7.3846e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 184 - 100% - 9.9257e-01 - 8.9353e-01 - 7.0766e-01 - 7.2792e-02 - 2.6105e-02 - 4.6688e-02 - 1.7280e-02 -    6.16    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 184 - 100% - 7.3716e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 185 - 100% - 9.8544e-01 - 8.8930e-01 - 7.0399e-01 - 9.7860e-02 - 4.5156e-02 - 5.2704e-02 - 1.7151e-02 -    6.15    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 185 - 100% - 7.1825e-01 -    1.56    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 186 - 100% - 9.8240e-01 - 8.8495e-01 - 6.8923e-01 - 1.0789e-01 - 5.4873e-02 - 5.3019e-02 - 1.7022e-02 -    6.14    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 186 - 100% - 7.1855e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 187 - 100% - 9.8407e-01 - 8.8627e-01 - 6.8387e-01 - 9.3363e-02 - 4.6407e-02 - 4.6956e-02 - 1.6893e-02 -    6.24    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 187 - 100% - 7.3238e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 188 - 100% - 9.8923e-01 - 8.8789e-01 - 6.9862e-01 - 8.8125e-02 - 3.8167e-02 - 4.9958e-02 - 1.6763e-02 -    6.18    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 188 - 100% - 7.3388e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 189 - 100% - 9.9166e-01 - 8.9379e-01 - 7.0951e-01 - 7.2770e-02 - 2.5927e-02 - 4.6843e-02 - 1.6632e-02 -    6.23    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 189 - 100% - 7.3338e-01 -    1.57    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 190 - 100% - 9.8786e-01 - 8.9026e-01 - 7.0401e-01 - 8.5147e-02 - 3.7131e-02 - 4.8015e-02 - 1.6502e-02 -    6.12    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 190 - 100% - 7.3049e-01 -    1.57    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 191 - 100% - 9.8953e-01 - 8.9266e-01 - 7.0829e-01 - 8.4833e-02 - 3.4188e-02 - 5.0645e-02 - 1.6370e-02 -    6.12    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 191 - 100% - 7.4403e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 192 - 100% - 9.9044e-01 - 8.9192e-01 - 7.0994e-01 - 7.9015e-02 - 3.3282e-02 - 4.5733e-02 - 1.6239e-02 -    6.14    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 192 - 100% - 7.3676e-01 -    1.55    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 193 - 100% - 9.8711e-01 - 8.8763e-01 - 7.0543e-01 - 9.1750e-02 - 4.1236e-02 - 5.0514e-02 - 1.6107e-02 -    6.13    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 193 - 100% - 7.3358e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 194 - 100% - 9.8802e-01 - 8.9107e-01 - 7.0071e-01 - 8.4974e-02 - 3.7738e-02 - 4.7237e-02 - 1.5974e-02 -    6.19    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 194 - 100% - 7.3965e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 195 - 100% - 9.8847e-01 - 8.9620e-01 - 7.0934e-01 - 8.4860e-02 - 3.6810e-02 - 4.8050e-02 - 1.5841e-02 -    6.13    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 195 - 100% - 7.3318e-01 -    1.62    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 196 - 100% - 9.9181e-01 - 8.9295e-01 - 7.0925e-01 - 7.8423e-02 - 2.8983e-02 - 4.9439e-02 - 1.5708e-02 -    6.13    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 196 - 100% - 7.2890e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 197 - 100% - 9.8953e-01 - 8.9136e-01 - 7.0457e-01 - 8.3872e-02 - 3.3339e-02 - 5.0533e-02 - 1.5574e-02 -    6.25    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 197 - 100% - 7.3039e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 198 - 100% - 9.8726e-01 - 8.9098e-01 - 6.9962e-01 - 8.4633e-02 - 3.8719e-02 - 4.5914e-02 - 1.5439e-02 -    6.15    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 198 - 100% - 7.3617e-01 -    1.56    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 199 - 100% - 9.8877e-01 - 8.9240e-01 - 7.0159e-01 - 8.1378e-02 - 3.2704e-02 - 4.8674e-02 - 1.5305e-02 -    6.14    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 199 - 100% - 7.2422e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 200 - 100% - 9.9090e-01 - 8.9489e-01 - 7.0498e-01 - 7.5725e-02 - 2.8492e-02 - 4.7233e-02 - 1.5170e-02 -    6.15    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 200 - 100% - 7.2422e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 201 - 100% - 9.8968e-01 - 8.9230e-01 - 7.0522e-01 - 8.0153e-02 - 3.1492e-02 - 4.8661e-02 - 1.5034e-02 -    6.23    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 201 - 100% - 7.3656e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 202 - 100% - 9.9075e-01 - 8.9101e-01 - 7.0887e-01 - 7.4164e-02 - 2.7852e-02 - 4.6311e-02 - 1.4898e-02 -    6.13    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 202 - 100% - 7.4264e-01 -    1.55    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 203 - 100% - 9.9211e-01 - 8.9499e-01 - 7.1853e-01 - 7.3971e-02 - 2.6821e-02 - 4.7150e-02 - 1.4762e-02 -    6.32    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 203 - 100% - 7.4104e-01 -    1.56    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 204 - 100% - 9.9378e-01 - 8.9694e-01 - 7.1807e-01 - 6.7640e-02 - 2.2053e-02 - 4.5588e-02 - 1.4625e-02 -    6.23    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 204 - 100% - 7.3796e-01 -    1.57    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 205 - 100% - 9.9242e-01 - 8.9624e-01 - 7.1910e-01 - 7.5260e-02 - 2.6913e-02 - 4.8347e-02 - 1.4488e-02 -    6.25    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 205 - 100% - 7.3149e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 206 - 100% - 9.9166e-01 - 8.9529e-01 - 7.1025e-01 - 7.7601e-02 - 2.9795e-02 - 4.7807e-02 - 1.4350e-02 -    6.18    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 206 - 100% - 7.3676e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 207 - 100% - 9.9302e-01 - 8.9766e-01 - 7.1609e-01 - 6.9081e-02 - 2.2380e-02 - 4.6701e-02 - 1.4212e-02 -    6.17    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 207 - 100% - 7.3408e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 208 - 100% - 9.9120e-01 - 8.9432e-01 - 7.1484e-01 - 7.4767e-02 - 2.6483e-02 - 4.8284e-02 - 1.4074e-02 -    6.28    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 208 - 100% - 7.3746e-01 -    1.62    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 209 - 100% - 9.9090e-01 - 8.9496e-01 - 7.1504e-01 - 7.8143e-02 - 3.0013e-02 - 4.8130e-02 - 1.3935e-02 -    6.20    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 209 - 100% - 7.3796e-01 -    1.56    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 210 - 100% - 9.8908e-01 - 8.9592e-01 - 7.1123e-01 - 8.3294e-02 - 3.6809e-02 - 4.6486e-02 - 1.3796e-02 -    6.14    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 210 - 100% - 7.1676e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 211 - 100% - 9.9105e-01 - 8.9123e-01 - 7.0734e-01 - 8.4532e-02 - 3.3323e-02 - 5.1209e-02 - 1.3656e-02 -    6.19    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 211 - 100% - 7.3477e-01 -    1.56    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 212 - 100% - 9.9075e-01 - 8.9407e-01 - 7.1014e-01 - 7.3029e-02 - 2.8056e-02 - 4.4973e-02 - 1.3517e-02 -    6.10    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 212 - 100% - 7.2980e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 213 - 100% - 9.9181e-01 - 8.9460e-01 - 7.1617e-01 - 7.2317e-02 - 2.5297e-02 - 4.7021e-02 - 1.3376e-02 -    6.13    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 213 - 100% - 7.4184e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 214 - 100% - 9.9150e-01 - 8.9864e-01 - 7.2393e-01 - 7.4867e-02 - 2.7441e-02 - 4.7426e-02 - 1.3236e-02 -    6.19    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 214 - 100% - 7.3428e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 215 - 100% - 9.9014e-01 - 9.0015e-01 - 7.0973e-01 - 7.6925e-02 - 3.0531e-02 - 4.6394e-02 - 1.3095e-02 -    6.15    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 215 - 100% - 7.3378e-01 -    1.62    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 216 - 100% - 9.9059e-01 - 8.9547e-01 - 7.1522e-01 - 7.6922e-02 - 2.9964e-02 - 4.6958e-02 - 1.2953e-02 -    6.16    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 216 - 100% - 7.3079e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 217 - 100% - 9.9499e-01 - 8.9678e-01 - 7.1276e-01 - 6.6277e-02 - 1.8956e-02 - 4.7321e-02 - 1.2812e-02 -    6.16    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 217 - 100% - 7.3517e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 218 - 100% - 9.9575e-01 - 9.0008e-01 - 7.2051e-01 - 6.0784e-02 - 1.7363e-02 - 4.3421e-02 - 1.2670e-02 -    6.12    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 218 - 100% - 7.3766e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 219 - 100% - 9.9545e-01 - 8.9911e-01 - 7.2484e-01 - 6.2746e-02 - 1.6515e-02 - 4.6231e-02 - 1.2527e-02 -    6.25    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 219 - 100% - 7.3836e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 220 - 100% - 9.9257e-01 - 9.0328e-01 - 7.2758e-01 - 6.5201e-02 - 2.3123e-02 - 4.2078e-02 - 1.2385e-02 -    6.15    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 220 - 100% - 7.3676e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 221 - 100% - 9.9333e-01 - 8.9964e-01 - 7.2161e-01 - 6.7074e-02 - 2.3313e-02 - 4.3761e-02 - 1.2242e-02 -    6.16    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 221 - 100% - 7.4244e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 222 - 100% - 9.9621e-01 - 9.0195e-01 - 7.3023e-01 - 5.8418e-02 - 1.4576e-02 - 4.3842e-02 - 1.2098e-02 -    6.17    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 222 - 100% - 7.4781e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 223 - 100% - 9.9059e-01 - 8.9717e-01 - 7.2139e-01 - 7.6891e-02 - 3.0258e-02 - 4.6632e-02 - 1.1954e-02 -    6.12    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 223 - 100% - 7.3746e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 224 - 100% - 9.9211e-01 - 8.9695e-01 - 7.2336e-01 - 7.2501e-02 - 2.4255e-02 - 4.8246e-02 - 1.1810e-02 -    6.22    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 224 - 100% - 7.2990e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 225 - 100% - 9.9378e-01 - 9.0046e-01 - 7.2293e-01 - 6.2878e-02 - 2.0736e-02 - 4.2142e-02 - 1.1666e-02 -    6.15    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 225 - 100% - 7.3746e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 226 - 100% - 9.9439e-01 - 9.0043e-01 - 7.2066e-01 - 6.2945e-02 - 1.8532e-02 - 4.4414e-02 - 1.1521e-02 -    6.14    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 226 - 100% - 7.4323e-01 -    1.56    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 227 - 100% - 9.9135e-01 - 8.9885e-01 - 7.2454e-01 - 7.0141e-02 - 2.5504e-02 - 4.4637e-02 - 1.1376e-02 -    6.13    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 227 - 100% - 7.4920e-01 -    1.57    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 228 - 100% - 9.9302e-01 - 9.0450e-01 - 7.2641e-01 - 6.3476e-02 - 2.1359e-02 - 4.2118e-02 - 1.1231e-02 -    6.22    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 228 - 100% - 7.4532e-01 -    1.57    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 229 - 100% - 9.9545e-01 - 9.0231e-01 - 7.3483e-01 - 6.1700e-02 - 1.4383e-02 - 4.7317e-02 - 1.1085e-02 -    6.11    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 229 - 100% - 7.4443e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 230 - 100% - 9.9393e-01 - 9.0110e-01 - 7.3305e-01 - 6.4690e-02 - 2.0295e-02 - 4.4395e-02 - 1.0939e-02 -    6.15    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 230 - 100% - 7.3836e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 231 - 100% - 9.9317e-01 - 9.0052e-01 - 7.2935e-01 - 6.5742e-02 - 2.1421e-02 - 4.4321e-02 - 1.0793e-02 -    6.14    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 231 - 100% - 7.3189e-01 -    1.56    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 232 - 100% - 9.9515e-01 - 9.0185e-01 - 7.2323e-01 - 6.2294e-02 - 1.9260e-02 - 4.3034e-02 - 1.0647e-02 -    6.27    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 232 - 100% - 7.4293e-01 -    1.57    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 233 - 100% - 9.9363e-01 - 9.0210e-01 - 7.2874e-01 - 6.5867e-02 - 1.9827e-02 - 4.6039e-02 - 1.0500e-02 -    6.13    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 233 - 100% - 7.3945e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 234 - 100% - 9.9484e-01 - 9.0405e-01 - 7.3475e-01 - 6.0333e-02 - 1.8349e-02 - 4.1984e-02 - 1.0353e-02 -    6.19    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 234 - 100% - 7.4871e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 235 - 100% - 9.9454e-01 - 9.0601e-01 - 7.3833e-01 - 6.3947e-02 - 2.0087e-02 - 4.3860e-02 - 1.0205e-02 -    6.11    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 235 - 100% - 7.4184e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 236 - 100% - 9.9560e-01 - 9.0544e-01 - 7.3409e-01 - 5.4343e-02 - 1.4295e-02 - 4.0048e-02 - 1.0058e-02 -    6.15    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 236 - 100% - 7.5080e-01 -    1.57    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 237 - 100% - 9.9681e-01 - 9.0687e-01 - 7.4451e-01 - 5.1923e-02 - 1.1942e-02 - 3.9981e-02 - 9.9097e-03 -    6.15    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 237 - 100% - 7.3965e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 238 - 100% - 9.9590e-01 - 9.0650e-01 - 7.3732e-01 - 5.6996e-02 - 1.4726e-02 - 4.2270e-02 - 9.7615e-03 -    6.13    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 238 - 100% - 7.5000e-01 -    1.57    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 239 - 100% - 9.9681e-01 - 9.0930e-01 - 7.4851e-01 - 4.9502e-02 - 9.7559e-03 - 3.9746e-02 - 9.6131e-03 -    6.14    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 239 - 100% - 7.5368e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 240 - 100% - 9.9590e-01 - 9.0905e-01 - 7.4673e-01 - 5.5210e-02 - 1.3038e-02 - 4.2172e-02 - 9.4643e-03 -    6.14    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 240 - 100% - 7.5269e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 241 - 100% - 9.9742e-01 - 9.0787e-01 - 7.4390e-01 - 5.1933e-02 - 1.2108e-02 - 3.9825e-02 - 9.3153e-03 -    6.29    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 241 - 100% - 7.4413e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 242 - 100% - 9.9681e-01 - 9.0851e-01 - 7.4666e-01 - 5.2881e-02 - 1.0826e-02 - 4.2055e-02 - 9.1661e-03 -    6.13    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 242 - 100% - 7.4771e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 243 - 100% - 9.9515e-01 - 9.0956e-01 - 7.4642e-01 - 5.5755e-02 - 1.6728e-02 - 3.9027e-02 - 9.0166e-03 -    6.13    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 243 - 100% - 7.4552e-01 -    1.56    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 244 - 100% - 9.9590e-01 - 9.0585e-01 - 7.4186e-01 - 5.6442e-02 - 1.3322e-02 - 4.3120e-02 - 8.8668e-03 -    6.18    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 244 - 100% - 7.4174e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 245 - 100% - 9.9560e-01 - 9.1001e-01 - 7.4699e-01 - 5.2447e-02 - 1.4519e-02 - 3.7928e-02 - 8.7168e-03 -    6.15    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 245 - 100% - 7.3826e-01 -    1.56    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 246 - 100% - 9.9560e-01 - 9.0705e-01 - 7.4103e-01 - 5.6049e-02 - 1.5324e-02 - 4.0725e-02 - 8.5666e-03 -    6.18    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 246 - 100% - 7.4064e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 247 - 100% - 9.9484e-01 - 9.0813e-01 - 7.4730e-01 - 5.7462e-02 - 1.5204e-02 - 4.2259e-02 - 8.4161e-03 -    6.20    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 247 - 100% - 7.5060e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 248 - 100% - 9.9515e-01 - 9.0712e-01 - 7.4108e-01 - 6.0380e-02 - 1.6035e-02 - 4.4346e-02 - 8.2654e-03 -    6.28    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 248 - 100% - 7.3826e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 249 - 100% - 9.9621e-01 - 9.0928e-01 - 7.4315e-01 - 5.2660e-02 - 1.2025e-02 - 4.0635e-02 - 8.1145e-03 -    6.13    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 249 - 100% - 7.4930e-01 -    1.56    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 250 - 100% - 9.9666e-01 - 9.0721e-01 - 7.4436e-01 - 5.3581e-02 - 1.2537e-02 - 4.1044e-02 - 7.9633e-03 -    6.13    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 250 - 100% - 7.3646e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 251 - 100% - 9.9666e-01 - 9.0684e-01 - 7.4363e-01 - 5.3836e-02 - 1.1409e-02 - 4.2427e-02 - 7.8120e-03 -    6.13    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 251 - 100% - 7.4821e-01 -    1.55    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 252 - 100% - 9.9863e-01 - 9.0917e-01 - 7.4670e-01 - 4.6808e-02 - 7.4110e-03 - 3.9397e-02 - 7.6604e-03 -    6.24    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 252 - 100% - 7.4741e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 253 - 100% - 9.9788e-01 - 9.1423e-01 - 7.5448e-01 - 4.4468e-02 - 8.1303e-03 - 3.6338e-02 - 7.5086e-03 -    6.19    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 253 - 100% - 7.5189e-01 -    1.57    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 254 - 100% - 9.9757e-01 - 9.1221e-01 - 7.5580e-01 - 4.9751e-02 - 8.8841e-03 - 4.0867e-02 - 7.3566e-03 -    6.11    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 254 - 100% - 7.4970e-01 -    1.56    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 255 - 100% - 9.9772e-01 - 9.1300e-01 - 7.5305e-01 - 4.7587e-02 - 8.6806e-03 - 3.8907e-02 - 7.2044e-03 -    6.13    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 255 - 100% - 7.4413e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 256 - 100% - 9.9772e-01 - 9.0900e-01 - 7.4979e-01 - 4.9910e-02 - 8.2454e-03 - 4.1665e-02 - 7.0520e-03 -    6.15    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 256 - 100% - 7.4672e-01 -    1.57    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 257 - 100% - 9.9818e-01 - 9.1416e-01 - 7.5644e-01 - 4.6009e-02 - 8.2091e-03 - 3.7800e-02 - 6.8995e-03 -    6.22    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 257 - 100% - 7.4881e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 258 - 100% - 9.9697e-01 - 9.1317e-01 - 7.5796e-01 - 4.5625e-02 - 9.6428e-03 - 3.5983e-02 - 6.7467e-03 -    6.12    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 258 - 100% - 7.4473e-01 -    1.56    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 259 - 100% - 9.9757e-01 - 9.1145e-01 - 7.5497e-01 - 5.0877e-02 - 1.1367e-02 - 3.9509e-02 - 6.5937e-03 -    6.13    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 259 - 100% - 7.4920e-01 -    1.62    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 260 - 100% - 9.9788e-01 - 9.1222e-01 - 7.5362e-01 - 5.1246e-02 - 1.0929e-02 - 4.0317e-02 - 6.4406e-03 -    6.13    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 260 - 100% - 7.4920e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 261 - 100% - 9.9894e-01 - 9.1309e-01 - 7.5935e-01 - 4.3199e-02 - 5.7629e-03 - 3.7436e-02 - 6.2873e-03 -    6.15    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 261 - 100% - 7.4453e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 262 - 100% - 9.9727e-01 - 9.1594e-01 - 7.6099e-01 - 4.6955e-02 - 8.7834e-03 - 3.8172e-02 - 6.1338e-03 -    6.13    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 262 - 100% - 7.4035e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 263 - 100% - 9.9788e-01 - 9.1539e-01 - 7.5971e-01 - 4.5991e-02 - 8.5563e-03 - 3.7435e-02 - 5.9801e-03 -    6.11    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 263 - 100% - 7.4413e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 264 - 100% - 9.9879e-01 - 9.1339e-01 - 7.5705e-01 - 4.0419e-02 - 5.5436e-03 - 3.4875e-02 - 5.8263e-03 -    6.14    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 264 - 100% - 7.4015e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 265 - 100% - 9.9909e-01 - 9.1807e-01 - 7.6123e-01 - 3.9905e-02 - 5.3163e-03 - 3.4589e-02 - 5.6723e-03 -    6.18    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 265 - 100% - 7.5239e-01 -    1.57    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 266 - 100% - 9.9818e-01 - 9.1721e-01 - 7.6073e-01 - 4.1487e-02 - 7.1232e-03 - 3.4364e-02 - 5.5182e-03 -    6.14    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 266 - 100% - 7.5109e-01 -    1.62    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 267 - 100% - 9.9909e-01 - 9.1512e-01 - 7.5909e-01 - 3.9590e-02 - 5.2787e-03 - 3.4312e-02 - 5.3639e-03 -    6.13    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 267 - 100% - 7.5707e-01 -    1.56    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 268 - 100% - 9.9833e-01 - 9.2178e-01 - 7.6620e-01 - 3.8610e-02 - 5.8177e-03 - 3.2792e-02 - 5.2095e-03 -    6.21    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 268 - 100% - 7.5627e-01 -    1.62    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 269 - 100% - 9.9863e-01 - 9.1731e-01 - 7.6536e-01 - 4.0931e-02 - 5.7674e-03 - 3.5163e-02 - 5.0549e-03 -    6.22    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 269 - 100% - 7.5149e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 270 - 100% - 9.9742e-01 - 9.1688e-01 - 7.6501e-01 - 4.2593e-02 - 6.5384e-03 - 3.6055e-02 - 4.9002e-03 -    6.19    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 270 - 100% - 7.5010e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 271 - 100% - 9.9818e-01 - 9.1704e-01 - 7.6455e-01 - 4.1908e-02 - 6.6811e-03 - 3.5227e-02 - 4.7454e-03 -    6.16    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 271 - 100% - 7.5657e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 272 - 100% - 9.9909e-01 - 9.1763e-01 - 7.6765e-01 - 4.0462e-02 - 4.4015e-03 - 3.6061e-02 - 4.5904e-03 -    6.26    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 272 - 100% - 7.5020e-01 -    1.62    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 273 - 100% - 9.9924e-01 - 9.1701e-01 - 7.6595e-01 - 3.9173e-02 - 4.1189e-03 - 3.5055e-02 - 4.4353e-03 -    6.21    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 273 - 100% - 7.4811e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 274 - 100% - 9.9909e-01 - 9.1785e-01 - 7.6661e-01 - 4.1458e-02 - 4.5686e-03 - 3.6889e-02 - 4.2801e-03 -    6.11    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 274 - 100% - 7.4781e-01 -    1.56    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 275 - 100% - 9.9894e-01 - 9.1764e-01 - 7.6627e-01 - 3.9055e-02 - 5.1212e-03 - 3.3934e-02 - 4.1248e-03 -    6.15    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 275 - 100% - 7.5109e-01 -    1.56    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 276 - 100% - 9.9848e-01 - 9.2055e-01 - 7.6955e-01 - 4.0540e-02 - 5.7633e-03 - 3.4777e-02 - 3.9693e-03 -    6.15    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 276 - 100% - 7.5338e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 277 - 100% - 9.9863e-01 - 9.2041e-01 - 7.7243e-01 - 3.7364e-02 - 4.8985e-03 - 3.2466e-02 - 3.8138e-03 -    6.15    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 277 - 100% - 7.5607e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 278 - 100% - 9.9894e-01 - 9.2253e-01 - 7.7351e-01 - 3.8752e-02 - 4.3301e-03 - 3.4422e-02 - 3.6581e-03 -    6.14    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 278 - 100% - 7.5388e-01 -    1.61    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 279 - 100% - 9.9970e-01 - 9.2286e-01 - 7.7239e-01 - 3.6341e-02 - 2.9638e-03 - 3.3377e-02 - 3.5023e-03 -    6.11    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 279 - 100% - 7.5169e-01 -    1.55    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 280 - 100% - 9.9939e-01 - 9.2033e-01 - 7.7186e-01 - 3.5809e-02 - 3.7392e-03 - 3.2070e-02 - 3.3465e-03 -    6.23    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 280 - 100% - 7.4940e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 281 - 100% - 9.9939e-01 - 9.2129e-01 - 7.7770e-01 - 3.5702e-02 - 2.9497e-03 - 3.2752e-02 - 3.1905e-03 -    6.17    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 281 - 100% - 7.5428e-01 -    1.62    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 282 - 100% - 9.9970e-01 - 9.2308e-01 - 7.7468e-01 - 3.8801e-02 - 3.7967e-03 - 3.5005e-02 - 3.0345e-03 -    6.25    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 282 - 100% - 7.4751e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 283 - 100% - 9.9985e-01 - 9.2176e-01 - 7.7624e-01 - 3.5189e-02 - 2.4082e-03 - 3.2781e-02 - 2.8784e-03 -    6.20    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 283 - 100% - 7.4791e-01 -    1.56    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 284 - 100% - 9.9985e-01 - 9.2297e-01 - 7.7983e-01 - 3.2926e-02 - 2.5798e-03 - 3.0346e-02 - 2.7222e-03 -    6.14    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 284 - 100% - 7.5199e-01 -    1.57    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 285 - 100% - 9.9970e-01 - 9.2622e-01 - 7.8520e-01 - 3.2952e-02 - 2.5966e-03 - 3.0356e-02 - 2.5659e-03 -    6.19    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 285 - 100% - 7.4801e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 286 - 100% - 9.9970e-01 - 9.2824e-01 - 7.8637e-01 - 3.3545e-02 - 2.4160e-03 - 3.1129e-02 - 2.4096e-03 -    6.15    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 286 - 100% - 7.4920e-01 -    1.58    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 287 - 100% - 9.9970e-01 - 9.2628e-01 - 7.8405e-01 - 3.4445e-02 - 2.2170e-03 - 3.2228e-02 - 2.2531e-03 -    6.13    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 287 - 100% - 7.4761e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 288 - 100% - 9.9985e-01 - 9.2402e-01 - 7.8193e-01 - 3.1672e-02 - 1.8519e-03 - 2.9820e-02 - 2.0967e-03 -    6.14    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 288 - 100% - 7.5348e-01 -    1.56    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 289 - 100% - 9.9970e-01 - 9.2545e-01 - 7.8491e-01 - 3.5378e-02 - 2.9704e-03 - 3.2408e-02 - 1.9401e-03 -    6.14    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 289 - 100% - 7.5299e-01 -    1.56    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 290 - 100% - 9.9909e-01 - 9.2597e-01 - 7.8481e-01 - 3.4731e-02 - 3.9141e-03 - 3.0817e-02 - 1.7836e-03 -    6.18    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 290 - 100% - 7.5348e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 291 - 100% - 9.9985e-01 - 9.2705e-01 - 7.8414e-01 - 3.1959e-02 - 1.7737e-03 - 3.0185e-02 - 1.6269e-03 -    6.17    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 291 - 100% - 7.5418e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 292 - 100% - 9.9985e-01 - 9.2599e-01 - 7.8564e-01 - 3.5166e-02 - 1.9068e-03 - 3.3260e-02 - 1.4703e-03 -    6.25    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 292 - 100% - 7.5318e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 293 - 100% - 1.0000e+00 - 9.2551e-01 - 7.8089e-01 - 3.1679e-02 - 1.7265e-03 - 2.9952e-02 - 1.3136e-03 -    6.27    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 293 - 100% - 7.5249e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 294 - 100% - 9.9970e-01 - 9.2608e-01 - 7.8311e-01 - 3.1348e-02 - 2.1285e-03 - 2.9219e-02 - 1.1568e-03 -    6.17    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 294 - 100% - 7.5030e-01 -    1.62    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 295 - 100% - 9.9985e-01 - 9.2722e-01 - 7.8409e-01 - 3.1896e-02 - 1.9115e-03 - 2.9984e-02 - 1.0000e-03 -    6.30    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 295 - 100% - 7.5050e-01 -    1.62    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 296 - 100% - 9.9985e-01 - 9.2683e-01 - 7.8761e-01 - 3.1776e-02 - 1.6669e-03 - 3.0109e-02 - 8.4321e-04 -    6.21    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 296 - 100% - 7.4980e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 297 - 100% - 9.9985e-01 - 9.2518e-01 - 7.8564e-01 - 3.0424e-02 - 2.3972e-03 - 2.8027e-02 - 6.8638e-04 -    6.24    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 297 - 100% - 7.5229e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 298 - 100% - 9.9970e-01 - 9.2765e-01 - 7.8592e-01 - 3.0962e-02 - 1.7319e-03 - 2.9231e-02 - 5.2953e-04 -    6.19    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 298 - 100% - 7.5239e-01 -    1.59    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 299 - 100% - 1.0000e+00 - 9.2877e-01 - 7.8916e-01 - 2.9364e-02 - 1.7335e-03 - 2.7630e-02 - 3.7266e-04 -    6.15    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 299 - 100% - 7.5318e-01 -    1.60    -\r\n",
      "\n",
      "-      train       -   acc_s    -   acc_u    - labels_use -    loss    -   loss_s   -   loss_u   -     lr     -  took (s)  -\n",
      "- Epoch 300 - 100% - 9.9985e-01 - 9.2944e-01 - 7.8880e-01 - 3.0815e-02 - 1.8634e-03 - 2.8952e-02 - 2.1579e-04 -    6.15    -\r\n",
      "-       val        -    acc     -  took (s)  -\n",
      "- Epoch 300 - 100% - 7.5299e-01 -    1.60    -\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for e in range(nb_epochs):\n",
    "\ttrain(e)\n",
    "\twith torch.no_grad():\n",
    "\t\tval(e)\n",
    "\tif scheduler is not None:\n",
    "\t\tscheduler.step()\n",
    "\tprint(\"\")\n",
    "\n",
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}